This section describes the experimental validation carried out to study the performance and
to get a clear understanding of the particularities of \VSDMOEA{}.
%
Results clearly show that controlling the diversity in the variable space is a way to improve further some of the results 
obtained by the state-of-art \MOEAS{}.
%
First, some technical specifications of the benchmark problems and implemented algorithms are discussed.
%
Thereafter, a comparison between \VSDMOEA{} and state-of-the-art algorithms is presented.
%
Then, three additional experiments to fully validate \VSDMOEA{} are included.
%
Such analyses are designed to test the scalability in the decision variable space, the performance with different stopping criteria, 
and the behavior with different initial penalty thresholds.

This work takes into account some of the most popular benchmarks that are widely applied in the multi-objective field.
%
Such problems are the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009} configured in a 
standard way.
%
The WFG test problems were used with two and three objectives
and configured with $24$ parameters, where $20$ of them correspond to distance parameters and $4$ to position parameters.
%
In the DTLZ test problems, the number of decision variables was set to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7, respectively.
% 
The UF benchmark comprises seven problems with two objectives (UF1-7) and three problems with three objectives (UF8-10).
%
All of them were configured with $30$ decision variables.

The experimental validation includes three well-known state-of-the-art-MOEAs and \VSDMOEA{}.
%
The \MOEAS{} that are taken into account are \NSGAII{}~\cite{Joel:jMetal}, \MOEAD{}~\cite{MOEADCode}, and \RMOEA{}~\cite{R2EMOACode}, 
which can be classified as dominance-based, decomposition-based, and indicator-based, respectively.
%
In the case of \MOEAD{} several variants have been devised.
%
The \MOEAD{} implementation that has been considered is the one that attained the first place in the Congress on Evolutionary Computation 
2009 MOP Competition~\cite{zhang2009performance}.

Given that all the considered algorithms are stochastic, each execution was repeated $35$ times with different seeds.
%
In order to compare the different schemes, the hypervolume indicator (\HV{}) is used.
%
Note that in the supplementary material they are also compared with the IGD+ and conclusions are similar.
%
The reference point used to calculate the \HV{} is chosen to be a vector whose values are sightly larger (ten percent) than the nadir point 
as is suggested in~\cite{ishibuchi2017reference}.
%
In order to facilitate the interpretation of the attained results, the normalized \HV{} is used~\cite{li2015evolutionary}
and the value reported is computed as the ratio between the normalized \HV{} reached and the maximum attainable 
normalized \HV{}.
%
In this way, a value equal to one means a perfect approximation.
%
Note that a value equal to one is not attainable because a discrete approximation is obtained by \MOEAS{}.
%
In order to statistically compare the \HV{} ratios, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whatever or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the non-parametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, and the mean and median \HV{} ratio 
obtained by $X$ are higher than the mean and median achieved by $Y$.

Our first experiment was devoted to compare the performance of \VSDMOEA{} against state-of-the-art proposals in the long-term.
%
The common configuration in all the executions was the following: the stopping criterion was set to $250,000$ generations, 
the population size was fixed to $100$, and the genetic operators were the Simulated Binary Crossover (SBX) and polynomial 
mutation~\cite{Joel:SBX1994, Joel:Mutation}.
%
The crossover probability was set to $0.9$ and the crossover distribution index was set to $2$.
%
Similarly, the mutation probability and distribution index were fixed to $1/n$ and $50$, respectively.
%
The additional parameterization required by each algorithm is shown in Table~\ref{tab:Parametrization}.
%
Note that in \MOEAD{} and \RMOEA{} scalarization functions are required.
%
In both cases the Tchebycheff approach is used.
%
The procedure to generate the weight vectors differs in \MOEAD{} and \RMOEA{}.
%
\RMOEA{} was applied with $501$ and $496$ weight vectors for two and three objectives respectively~\cite{trautmann2013r2}.
%
Differently, \MOEAD{} requires the same number of weight vectors than the population size.
%
They were generated with the uniform design (UD) and the good lattice point method (GLP)~\cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres}.



%
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[t]
\centering
\caption{Parameterization of each MOEA}
\label{tab:Parametrization}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{\textbf{MOEA/D}} &Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbor size = 10, \\
 & period utility updating = 30 generations, \\ 
 & local selection probability ($\delta$) = 0.9,\\ \hline
\textbf{VSD-MOEA} & $D_I=0.4$ \\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\end{tabular}
\end{table}



\input{Tables/Table_HV_2obj.tex}
\input{Tables/Table_HV_3obj.tex}

Tables \ref{tab:StatisticsHV_2obj} shows the attained \HV{} ratio for the benchmark functions
with two objectives.
%
Specifically, the minimum, maximum, mean and standard deviation of the \HV{} ratio is shown for each tested method and function.
%
The last row shows the results considering all the functions together.
%
In each function, the data of the method that attained the largest mean is shown in bold face.
%
Additionally, all the methods that were not statistically inferior than such a method are shown in bold face.
%
From here on, the methods shown in bold face in a given problem are reffered to as the winning methods.
%
Attending to the amount of functions where each method is shown is bold-face for the cases 
with two objectives, the best methods are \VSDMOEA{} and \RMOEA{} with 13 and 11, respectively.
%
Thus, while \VSDMOEA{} is the most competitive one, its superiority does not seem impressive
attending to these numbers.
%
However, the mean \HV{} ratio attained by \VSDMOEA{} when considering all the problems simultaneously is quite larger
than the one attained by \RMOEA{}.
%
In fact, the total mean of \RMOEA{} ($0.882$), \NSGAII{} ($0.886$) and \MOEAD{} ($0.881$) are quite similar.
%
In contrast \VSDMOEA{} achieved a much higher value ($0.951$).
%
If the data is inspected carefully, it is clear that when \VSDMOEA{} loses, the difference with respect to the
best method is not really large.
%
For instance, the difference between the \HV{} ratio attained by \VSDMOEA{} and by the best method was never larger
than $0.1$.
%
However, all the other methods presented a deteriation larger than $0.1$ in several cases.
%
Particularly, it happened in $5$, $5$ and $6$ problems for \RMOEA{}, \NSGAII{} and \MOEAD{}, respectively.
%
This means that even if \VSDMOEA{} loses in some cases, its deteriotation is always small showing a much more 
robust behaviour than any other method.

In order to better clarify these findings pair-wise statistical tests were done among each tested method in each
function.
%
Table~\ref{tab:Tests_HV_2obj} shows for the two-objective cases, the amount of times that each method won (column $\uparrow$),
lost (column $\downarrow$) and tied (column $\leftrightarrow$).
%
Additionally, for each method $M$ we calculated the sum of the differences between the mean \HV{} ratio attained by the best method (the ones with largest mean)
and the method $M$, for each problem where the best method won $M$.
%
This value is shown in the Total Deterioration column.
%
The calculated data confirms that the number of wins is close in \VSDMOEA{} and \RMOEA{}, but the total deterioration is quite lower in the case of \VSDMOEA{}.


Tables~\ref{tab:StatisticsHV_2obj} and \ref{tab:Tests_HV_2obj} shows the same information for the problems with three objectives.
%
In this case, the superiority of \VSDMOEA{} is even clearer.
%
Taking into account the mean of all functions, \VSDMOEA{} attained again a much larger mean \HV{} ratio than the other methods.
%
Particularly, \VSDMOEA{} attained the value $0.916$, whereas the second raked algorithm (\RMOEA{}) attained the value $0.855$.
%
Once again, the difference between the \HV{} ratio attained by \VSDMOEA{} and by the best method was never larger
than $0.1$.
%
However, all the other methods presented a deteriation larger than $0.1$ in several cases.
%
Particularly, it happened in $5$, $6$ and $6$ problems for \RMOEA{}, \NSGAII{} and \MOEAD{}, respectively.
%
Moreover, in this case, \VSDMOEA{} is much superior than the other methods not only in terms of total deterioration but also
in terms of total wins (see Table~\ref{tab:Tests_HV_2obj} and data shown in bold face).
%
\VSDMOEA{} was in the group of the winning methods in 17 out of 19 functions, whereas the second best ranked algorithm (\RMOEA{})
belonged to the group of winning methods only in 3 functions.

\subsection{Decision Variable Scalability Analysis}

In order to study the scalability of \VSDMOEA{} in terms of the number of decision variables, all the already described algorithms were tested with
the same benchmark functions but considering $50$, $100$, and $250$ variables.
%
Since increasing the number of variables highly increases the required computing time, this study takes into account middle-term executions ($25,000$ generations).
%
Figures \ref{fig:variable-decision-scalability-2obj} and \ref{fig:variable-decision-scalability-3obj} shows the mean \HV{} ratio for the four tested algorithms,
considering the problems with two and three objectives, respectively.
%
As expected, the \HV{} ratio decrease as the number of variables increases.
%
In the two-objective case, the deterioration is similar in every algorithm, so the superiority of \VSDMOEA{} is clear regardless of the amount of decision
variables.
%
Differently, in the three-objective case, the deterioration of \VSDMOEA{} is larger than the one of \RMOEA{} and \MOEAD{}.
%
In fact, when considering $250$ variables, the performance of \VSDMOEA{} is just slightly superior than the one of \RMOEA{}.


%In problems of three objectives, the \VSDMOEA{} performance seems to be more affected increasing the number of variables in comparison to the weight-vector based algorithms.
%
%This might by caused for several reasons, perhaps two of the most important are the stopping criterion which might not be enough to attain an adequately convergence and the distance metric taken into consideration for the management of diversity.
%
%The latter is popularly known as \textit{The Curse of Dimensionality} \cite{trunk1979problem, beyer1999nearest}, meaning that under certain broad conditions, as dimensionality is increased, the distance to the nearest neighbor tends to be the same to the farthest neighbor.
%
%In other words, the contrast in distances to different data points becomes no-existent.


\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Scalability-2obj_tikz-figure0.pdf}
\includegraphics[]{Images/Graphic-Scalability-2obj_tikz-figure0.eps}
%\input{Graphic-Scalability-2obj.tex}
\caption{Mean of the \HV{} (35 runs) considering two objectives.}\label{fig:variable-decision-scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Scalability-3obj_tikz-figure0.pdf}
\includegraphics[]{Images/Graphic-Scalability-3obj_tikz-figure0.eps}
%\input{Graphic-Scalability-3obj.tex}
\caption{Mean of the \HV{} (35 runs) considering three objectives.} \label{fig:variable-decision-scalability-3obj}
\end{figure}

In order to better understand this behaviour, we selected the WFG1 to WFG7 problems.
%
WFG problems divide the decision variables in two kinds of parameters: the distance parameters and the position parameters.
%
Note that, a parameter $i$ is a distance parameter when for all $\vec{\mathbf{x}}$, modifying $x_i$ results in a new solution 
that dominates $\vec{\mathbf{x}}$, is equivalent to $\vec{\mathbf{x}}$, or is dominated by $\vec{\mathbf{x}}$.
%
However, if $i$ is a position parameter, modifying $x_i$ in $\vec{\mathbf{x}}$ always results in a vector that is incomparable or 
equivalent to $\vec{\mathbf{x}}$~\cite{huband2005scalable}.
%
Additionally, note that we selected the WFG1-WFG7 problems because their distance parameters values associated to all Pareto optimal solutions 
have exactly the same values.
%
This values is shown as follows:
\begin{equation}
   x_{i=k+1:n} = 2i \times 0.35
\end{equation}
%
This is really important because it has been shown that for some cases, state-of-the-art
\MOEAS{} provoke a quick convergence in \textit{distance parameters}, resulting in an effect that is similar to premature convergence
in the single-objective case.

For each algorithms, we calculated the avarege Euclidean distance among individuals (ADI) in the population by considering only 
the distance parameters.
%
Figures \ref{fig:Diversity_2obj} and \ref{fig:Diversity_3obj} shows the ADI evolution for the two-objective and three-objective problems.
%
In order to not sature this Figures, only the information of \VSDMOEA{} and \RMOEA{} with 50, 100 and 250 decision variables is shown.

%
The first evident issue is that \VSDMOEA{} converges much slower than \RMOEA{}.
%
In this way, the difference between the diversity maintained in the first generation and the one maintained after 10\% of the execution,
is much larger in \RMOEA{} than in \VSDMOEA{}.
%
In the case of \VSDMOEA{}, the decrease in ADI is quite linear until the 50\% of the execution.
%
This is due to the way in which the threshold distance value ($D_t$) is calculated.
%
Additionally, when inspecting more closely the data, some other important aspects must be discussed. 
%
In the two-objective case, increasing the number of variables provokes a slight increase on the diversity in \RMOEA{}.
%
However, the amount of diversity is low even when using 250 distance variables, meaning that incorporating mechanisms to increase diversity --- as it is done in \VSDMOEA{} ---
is really helpful.
%
Differently, in the three-objective case, the amount of diversity in \RMOEA{} is not so low.
%
Moreover, increasing the number of decision variables, provokes an important increase in the attained ADI, meaning that in this case,
fast convergence is not an issue.
%
These results show that, as the number of objectives and variables increases, \MOEAS{} tend to maintain a higher variable-space diversity
in an implicity way, meaning that explicitly controlling the variable-space diversity is probably not so important.
%
Note that the behaviour of \NSGAII{} and \MOEAD{} in terms of the ADI evolution is similar to the one analyzed for \RMOEA{}.

Finally, we would like to note that we selected some specific problems to perform long-term executions with 250 distance variables.
%
\VSDMOEA{} could improve further the results when using long-term executions, while the other state-of-the-art algorithms dit not attain
important improvements.
%
This probably means that as the technology evolves and longer executions (more generations) can be performed in admisible times,
the incorporation of explicit control of diversity will be even more important.
%
Note that this also happens in the single-objective case, where benefits of explicit control of diversity appears only when using executions of
several weeks when dealing with large instances of the Traveling Salesman Problem.
%
TODO: PONER CITA.




\begin{figure}[t]
\centering
%\input{Graphic-Diversity_2obj.tex}
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure0.pdf} \\
\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure0.eps} \\[0.2cm]
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure1.pdf}
\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure1.eps}
\caption{Evolution of average distance individuals of the problems WFG1-WFG7 with two objectives.}\label{fig:Diversity_2obj}
\end{figure}



%
%

\begin{figure}[t]
\centering
%\input{Graphic-Diversity_3obj.tex}
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure0.pdf} \\
\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure0.eps} \\[0.2cm]
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure1.pdf}
\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure1.eps}
\caption{Evolution of average distance individuals of the problems WFG1-WFG7 with three objectives.}\label{fig:Diversity_3obj}
\end{figure}
%\begin{figure}[t]
%\centering
%\input{Graphic-Diversity_WFG6.tex}
%\label{fig:Diversity_WFG6}
%\end{figure}

\subsection{Stopping criteria and Diversity}


This section is devoted to test the performance of the algorithms with several stopping criteria, i.e. maximum number of generations.
%
As it is previously discussed, state-of-the-art algorithms might suffer of premature convergence or stagnation.
%
Therefore, the solutions could converge to promising --but not optimal-- regions at the first stages of the execution, wasting a meaningful quantity of generations.
%
To deal with this issue, \VSDMOEA{} maintains diversity at different stages as long as the stopping criterion is reached.
%
Accordingly, to have a better understanding of the performance obtained in each algorithm several stopping criteria have been probed.
%
In those runs the mean of normalized \HV{} of all the problems for two and three objectives are calculated.
%
Mainly, three ranges of stopping criterion were explored.
%
Each range was split in ten intervals, such ranges considered were $[250, 2500]$, $[2500, 25000]$ and $[25000, 250000]$ that are named as short-term, middle-term and long-term executions respectively.
%
In Figures \ref{fig:Performance_time_2obj} and \ref{fig:Performance_time_3obj} are showed the mean \HV{} values attained with each \MOEA{} with two and three objectives respectively.
%
Each figure is conformed by three graphics which correspond to short-term, middle-term and long-term.
%
Those figures demonstrate that \VSDMOEA{} attained competitive results considering short-term executions.
%
Even more, as the maximum number of generations is increased its performance is improved.
%
In fact after $2,500$ generations \VSDMOEA{} has a notorious improvement respect to the state-of-the-art-\MOEAS{} in both two and three objectives (second row of Figures \ref{fig:Performance_time_2obj} and \ref{fig:Performance_time_3obj}).
%
In problems of two objectives state-of-the-art algorithms attained quite similar \HV{} values in long-term executions ($250,000$ generations).
%
The weight-vector based algorithms had a similar behavior modificating the stopping criterion.
%
Particularly, \RMOEA{} improved state-of-the-art algorithms with problems of three objectives (Figure \ref{fig:Performance_time_3obj}).
%
Moreover, this algorithm showed a lightly constant improvement increasing the number of generations.
%
However, \VSDMOEA{} attained the best results in long-term executions and could improve even more increasing the time-execution.
%


\begin{figure}[t]
\centering
%\input{Graphic-Performance-Time.tex}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.eps} \\
\begin{tabular}{l}
 \includegraphics[scale=0.6]{Images/Time_tikz-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.6]{Images/Time_tikz-figure1.eps}\\[0cm]%[-0.18cm]
 \includegraphics[scale=0.6]{Images/Time_tikz-figure2.eps}
\end{tabular}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure1.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure1.eps}
\caption{Performance of the \MOEAS{} considering three ranges of stopping criterion. The configurations take place with short-term (first row), middle-term (second row) and long-term (third row) executions.}\label{fig:Performance_time_2obj}
\end{figure}

\begin{figure}[t]
\centering
%\input{Graphic-Performance-Time.tex}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.eps} \\
\begin{tabular}{l}
 \includegraphics[scale=0.6]{Images/Time_tikz-figure3.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.6]{Images/Time_tikz-figure4.eps}\\[0cm]%[-0.18cm]
 \includegraphics[scale=0.6]{Images/Time_tikz-figure5.eps}
\end{tabular}
\caption{Performance of the \MOEAS{} considering three ranges of stopping criterion. The configurations take place with short-term (first row), middle-term (second row) and long-term (third row) executions.}\label{fig:Performance_time_3obj}
\end{figure}


\subsection{Analysis of the Initial Threshold Value}

Avoidance of premature convergence and stagnation in long-term executions is a difficult task mainly in multi-objective problems since that --depending of the problem-- the objective space implicitly involves a relation of diversity in the decision variable space.
%
For this reason, a potential strategy to mitigate those drawbacks is to lead the algorithm through different diversity stages and taking into account the stopping criterion to stimulate an appropriate balance between exploration and exploitation.
%
Nevertheless, the latter strategy, which is Incorporated in \VSDMOEA{}, requires an initial parameter, which represents the initial diversity induced in the algorithm, better known as the initial threshold value ($D_I$).
%
Accordingly, this initial threshold value is decreasing as the time elapses.
%
In order, to have a better insight about the effect raised of inducing several initial diversity stages, \VSDMOEA{} is tested with several initial threshold values and in long-term executions ($250,000$ generations).
%
Particularly, this parameter is computed as a fraction of the main normalized diagonal, which belongs to the unitary hyper-cube, the portions considered are $D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\}$.
%
In Figure \ref{fig:Initial-distance-factor} is shown the general normalized mean of the \HV{} for each configuration with two an three objectives.
%
Specifically, setting $D_I=0.0$ implies that the diversity is not promoted resulting in a similar behavior as the dominance-based algorithm.
%
In spite of this setting, \VSDMOEA{} attained better \HV{} values with all the settings than the state-of-the-art algorithms, in fact the lowest values were attained without inducing diversity, such values were $0.912$ and $0.893$ for two and three objectives respectively.
%
Especially, the maximum benefit achieved of inducing diversity is found with an initial threshold value of $DI=0.4$ with two and three objectives.
%
In addition, the behavior of setting several initial threshold value is quite similar with two and three objectives.
%
Therefore, inducing diversity and taking into account the elapses generations can be useful mainly for middle-term and long-term executions.

\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Initial-Distance_tikz-figure0.pdf} \\
\includegraphics[]{Images/Graphic-Initial-Distance_tikz-figure0.eps} \\
%\input{Graphic-Initial-Distance.tex}
\caption{Mean of \HV{} values taking into account all instances with several initial threshold values.}\label{fig:Initial-distance-factor}
\end{figure}



%\input{Tables/Table_IGDP_2obj.tex}
%\input{Tables/Table_IGDP_3obj.tex}
\input{Tables/Tests_HV_2obj.tex}
\input{Tables/Tests_HV_3obj.tex}
%\input{Tables/Tests_IGDP_2obj.tex}
%\input{Tables/Tests_IGDP_3obj.tex}
