This section describes the experimental validation carried out to validate the performance and
to get a clear understanding of the particularities of \VSDMOEA{}.
%
Results clearly show that controlling the diversity in the variable space is a way to improve further some of the results 
obtained by the state-of-art \MOEAS{}.
%
First, some technical specifications of the benchmark problems and implemented algorithms are discussed.
%
Thereafter, a comparison between \VSDMOEA{} and state-of-the-art algorithms is presented.
%
Then, three additional experiments to fully validate \VSDMOEA{} are included.
%
Such analyses are designed to test the scalability in the decision variable space, the performance with different stopping criteria, 
and the behavior with different initial penalty thresholds.

This work takes into account some of the most popular benchmarks that are widely applied in the multi-objective field.
%
Such problems are the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009} configured in a quite
standard way.
%
The WFG test problems were used with two and three objectives
and configured with $24$ parameters, where $20$ of them correspond to distance parameters and $4$ to position parameters.
%
In the DTLZ test problems, the number of decision variables was set to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7, respectively.
% 
The UF benchmark comprises seven problems with two objectives (UF1-7) and three problems with three objectives (UF8-10).
%
All of them were configured with $30$ decision variables.

The experimental validation includes three well-known state-of-the-art-MOEAs and \VSDMOEA{}.
%
The \MOEAS{} that are taken into account are \NSGAII{}~\cite{Joel:jMetal}, \MOEAD{}~\cite{MOEADCode}, and \RMOEA{}~\cite{R2EMOACode}, 
which can be classified as dominance-based, decomposition-based, and indicator-based, respectively.
%
In the case of \MOEAD{} several variants have been devised.
%
The \MOEAD{} implementation that has been considered is the one that attained the first place in the Congress on Evolutionary Computation 
2009 MOP Competition~\cite{zhang2009performance}.
%
Given that all the considered algorithms are stochastic, each execution was repeated $35$ times with different seeds.

Our first experiment was devoted to compare the performance of \VSDMOEA{} against state-of-the-art proposals in the long-term.
%
The common configuration in all the executions was the following: the stopping criterion was set to $250,000$ generations, 
the population size was fixed to $100$, and the genetic operators were the Simulated Binary Crossover (SBX) and polynomial 
mutation~\cite{Joel:SBX1994, Joel:Mutation}.
%
Specifically, the crossover probability was set to $0.9$ and the crossover distribution index was
set to $2$.
%
Similarly, the mutation probability and distribution index were fixed to $1/n$ and $50$, respectively.
%
The additional parameterization required by each algorithm is shown in Table~\ref{tab:Parametrization}.
%
Note that in \MOEAD{} and \RMOEA{} scalarization functions are required.
%
In both cases the Tchebycheff approach is used.
%
The procedure to generate the weight vectors differs in \MOEAD{} and \RMOEA{}.
%
\RMOEA{} was applied with $501$ and $496$ weight vectors for two and three objectives respectively~\cite{trautmann2013r2}.
%
In contrast, \MOEAD{} requires the same number of weight vectors than the population size, therefore the weight vectors were generated with the uniform design (UD) and the good lattice point method (GLP)~\cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres}.



%
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[t]
\centering
\caption{Parameterization of each MOEA}
\label{tab:Parametrization}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{\textbf{MOEA/D}} &Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbor size = 10, \\
 & period utility updating = 30 generations, \\ 
 & probability local selection ($\delta$) = 0.9,\\ \hline
\textbf{VSD-MOEA} & $D_I=0.4$ \\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\end{tabular}
\end{table}



The experimental analyses were carried out taking into account the hyper-volume indicator (\HV{}).
%
The \HV{} metric measures the objective space dominated by the approximated solutions given a reference point, so the solutions dominated by the reference point were not considered.
%
Particularly, the reference point is chosen to be a vector whose values are sightly larger (ten percent) than the nadir point as is suggested in \cite{ishibuchi2017reference}.
%
Similarly that in \cite{li2015evolutionary}, and to have a fair comparison the normalized \HV{} is estimated.
%
Specifically, the \HV{} reported is computed as the ratio between the \HV{} reached by a set of solutions and the \HV{} of a set of points that belong to the Pareto Front.
%
In this way, the more approximated to the unity this metric is, the more converged are the solutions to the Pareto Front.
%

%
In order to statistically compare the \HV{} results, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whatever or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the non-parametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, if the mean and median obtained by $X$ are higher than the mean and median achieved by $Y$.
%

In Tables \ref{tab:StatisticsHV_2obj} and \ref{tab:StatisticsHV_3obj} are shown the normalized hyper-volume with two and three objectives respectively.
%
In this empirical results the \VSDMOEA{} achieved the best general mean and the lowest variability, therefore it is quite stable to different runs.
%
According to Table \ref{tab:StatisticsHV_2obj} the dominance-based algorithms improved the remaining MOEAs.
%
However, the general mean of \NSGAII{} (second best algorithm with $0.886$) is quite similar to \MOEAD{} ($0.881$) and \RMOEA{} ($0.882$), in contrast \VSDMOEA{} achieved the highest \HV{} value ($0.951$).
%
In particular, the dominance-based algorithms gave the best values in the kind of problems with disconnected Pareto geometries (WFG2, UF5 and UF6).
%
Differently, taking into account three objectives, \NSGAII{} was placed as the worst algorithm ($0.785$), perhaps provoked by its density estimator, which has some drawbacks in the most difficult problems with three objectives (e.g. multi-frontal problems).
%
The second place is attained by \RMOEA{} ($0.855$), which is still quite low compared with \VSDMOEA{} ($0.916$).
%


Given that the general mean can be unsteady to atypical measurements, i.e. high variability, in Tables \ref{tab:Tests_HV_2obj} and \ref{tab:Tests_HV_3obj} are shown the statistical tests with two and three objectives respectively.
%
In addition, those tables incorporate the difference between the mean of each algorithm and the best mean achieved for each problem, which is tagged with ``Diff''.
%
A representative value of each column is shown in the last row which is conformed by the sum of the entirely column.
%
The algorithm that attained more wins in the pairwise comparison is the \VSDMOEA{} with $48$ and $52$ wins in two and three objectives respectively.
%
Besides that \VSDMOEA{} lost in few pairwise comparisons, in such problems this algorithm is close enough to the best results, this can be seen through the small ``Diff'' values attained.
%
In fact, \VSDMOEA{} achieved $0.060$ and $0.027$ in contrast to the two second bests algorithms that are \NSGAII{} ($1.542$) and \RMOEA{} ($1.172$) for two and three objectives respectively.
%
Specifically, the worst ``Diff'' value achieved by the \VSDMOEA{} is with the WFG6 test-problem ($0.045$ and $0.024$), which is uni-modal and non-separable.
%
Nevertheless, this problem was better approximated with $D_I=0.1$ whose means were of $0.913$ and $0.868$ for two and three objectives respectively.
%
Indicating that this problem is improved inducing less diversity at the initial stages of the execution.
%

\subsection{Decision Variable Scalability Analysis}

In order, to study the scalability of the decision variables, and following the same configuration, the algorithms were test with $50$, $100$, and $250$ variables.
%
Particularly, since that long-term executions ($250,000$ generations) are time-consuming, this analysis is carried out taking into account middle-term executions ($25,000$ generations).
%
In Figures \ref{fig:variable-decision-scalability-2obj} and \ref{fig:variable-decision-scalability-3obj} are shown the normalized mean of the \HV{} results for two and three objectives respectively.
%
Especially, increasing the number of variables provoked a degradation to different levels on the performance of each algorithm.
%
Nevertheless, the based-dominance algorithms are the best with problems of two objectives.
%
In contrast, taking into account problems of three objectives, the weight-vector based algorithms showed to be more stable than the dominance-based algorithms.
%
%The former had similar performance increasing the number of decision variables.
%
However, \VSDMOEA{} is still the best algorithm in both two and three objectives.
% 
In problems of three objectives, the \VSDMOEA{} performance seems to be more affected increasing the number of variables in comparison to the weight-vector based algorithms.
%
This might by caused for several reasons, perhaps two of the most important are the stopping criterion which might not be enough to attain an adequately convergence and the distance metric taken into consideration for the management of diversity.
%
The latter is popularly known as \textit{The Curse of Dimensionality} \cite{trunk1979problem, beyer1999nearest}, meaning that under certain broad conditions, as dimensionality is increased, the distance to the nearest neighbor tends to be the same to the farthest neighbor.
%
In other words, the contrast in distances to different data points becomes no-existent.


\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Scalability-2obj_tikz-figure0.pdf}
\includegraphics[]{Images/Graphic-Scalability-2obj_tikz-figure0.eps}
%\input{Graphic-Scalability-2obj.tex}
\caption{Mean of the \HV{} (35 runs) considering two objectives.}\label{fig:variable-decision-scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Scalability-3obj_tikz-figure0.pdf}
\includegraphics[]{Images/Graphic-Scalability-3obj_tikz-figure0.eps}
%\input{Graphic-Scalability-3obj.tex}
\caption{Mean of the \HV{} (35 runs) considering three objectives.} \label{fig:variable-decision-scalability-3obj}
\end{figure}

In order, to have a better understanding of the algorithms and following the guideline of middle-term executions, the diversity in the decision variable space with some WFG problems is calculated.
%
Particularly, these problems divide the decision variables in two kinds of parameters: the distance parameters and the position parameters.
%
A parameter $x_i$ is a distance parameter when for all parameter vectors $\vec{F}(\mathbf{x})$, modifying $x_i$ in $\vec{F}(\mathbf{x})$ results in a parameter vector that dominates $\vec{F}(\mathbf{x})$, is equivalent to $\vec{F}(\mathbf{x})$, or is dominated by $\vec{F}(\mathbf{x})$.
%
However, if $x_i$ is a position parameter, modifying $x_i$ in $\vec{F}(\mathbf{x})$ always results in a vector that is incomparable or equivalent to $\vec{F}(\mathbf{x})$~\cite{huband2005scalable}.
%

%
Particularly, the selected problems were used to show that either premature convergence or stagnation appears in the set of distance parameters.
%
Consequently, the operators involved lose its exploratory strength.
%
We select the WFG1-WFG7 problems because their distance parameters values associated to Pareto optimal solutions have exactly the same values.
%
This values is shown as follows:
\begin{equation}
   x_{i=k+1:n} = 2i \times 0.35
\end{equation}
%
%
In order to analyze the diversity, the average Euclidean distance among individuals (ADI) is calculated, i.e. the mean value of all pairwise distances among individuals in the population is reported.
%
In Figures \ref{fig:Diversity_2obj} and \ref{fig:Diversity_3obj} are shown the evolution of diversity with two and three objectives.
%
Concretely, each figure shows the diversity maintained in the position parameters and the distance parameters.
%
The diversity is calculated with $50$, $100$, and $250$ variables for each algorithm.
%
Mainly, the state-of-the-art algorithms converged to promising regions in the distance parameters after the $10\%$ of the total time-execution.
%
However, their diversity in position parameters increases as the time elapses, meaning that the remaining $90\%$ is devoted to promote diverse solutions in the objective space.
%
In spite this, it seems that the algorithms converge on the distance parameters to promising regions, even though those regions could not be the optimal.
%
In contrast, \VSDMOEA{} keeps diverse solutions in both kind of parameters until the $90\%$ of the time elapsed, this strategy allows to explore more adequately the promising regions and might avoid stagnation in several stages.
%
\begin{figure}[t]
\centering
%\input{Graphic-Diversity_2obj.tex}
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure0.pdf} \\
\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure0.eps} \\[0.2cm]
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure1.pdf}
\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure1.eps}
\caption{Evolution of average distance individuals of the problems WFG1-WFG7 with two objectives.}\label{fig:Diversity_2obj}
\end{figure}



In relation with the state-of-the-art algorithms, the diversity maintained in problems of three objectives was larger than with problems of two objectives, this might occurs since that the quantity of prominent solutions increases meaningfully between two and three objectives.
%
Therefore, there is present an implicit relation of diversity between the number of objectives and the decision variables space, in this situation three objectives keeps implicitly more diversity than two objectives.
%
However, this implicit diversity maintained is not enough to avoid stagnation in several problems.
%
Thus, the consideration of long-term executions in the state-of-the-art algorithms could not provide meaningfully improvements.
%
In contrast, \VSDMOEA{} could improve even more with long-term executions, since that it keeps diversity at several stages.
%
In general, as the number of variables is increased, the convergence in the distance parameters is even more slow, therefore to have quality solutions should be required a greater time-execution, specifically in the diversity-based approaches.
%

\begin{figure}[t]
\centering
%\input{Graphic-Diversity_3obj.tex}
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure0.pdf} \\
\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure0.eps} \\[0.2cm]
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure1.pdf}
\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure1.eps}
\caption{Evolution of average distance individuals of the problems WFG1-WFG7 with three objectives.}\label{fig:Diversity_3obj}
\end{figure}
%\begin{figure}[t]
%\centering
%\input{Graphic-Diversity_WFG6.tex}
%\label{fig:Diversity_WFG6}
%\end{figure}

\subsection{Performance of \MOEAS{} Through the Execution}


This section is devoted to test the performance of the algorithms with several stopping criteria, i.e. maximum number of generations.
%
As it is previously discussed, state-of-the-art algorithms might suffer of premature convergence or stagnation.
%
Therefore, the solutions could converge to promising --but not optimal-- regions at the first stages of the execution, wasting a meaningful quantity of generations.
%
To deal with this issue, \VSDMOEA{} maintains diversity at different stages as long as the stopping criterion is reached.
%
Accordingly, to have a better understanding of the performance obtained in each algorithm several stopping criteria have been probed.
%
In those runs the mean of normalized \HV{} of all the problems for two and three objectives are calculated.
%
Mainly, three ranges of stopping criterion were explored.
%
Each range was split in ten intervals, such ranges considered were $[250, 2500]$, $[2500, 25000]$ and $[25000, 250000]$ that are named as short-term, middle-term and long-term executions respectively.
%
In Figures \ref{fig:Performance_time_2obj} and \ref{fig:Performance_time_3obj} are showed the mean \HV{} values attained with each \MOEA{} with two and three objectives respectively.
%
Each figure is conformed by three graphics which correspond to short-term, middle-term and long-term.
%
Those figures demonstrate that \VSDMOEA{} attained competitive results considering short-term executions.
%
Even more, as the maximum number of generations is increased its performance is improved.
%
In fact after $2,500$ generations \VSDMOEA{} has a notorious improvement respect to the state-of-the-art-\MOEAS{} in both two and three objectives (second row of Figures \ref{fig:Performance_time_2obj} and \ref{fig:Performance_time_3obj}).
%
In problems of two objectives state-of-the-art algorithms attained quite similar \HV{} values in long-term executions ($250,000$ generations).
%
The weight-vector based algorithms had a similar behavior modificating the stopping criterion.
%
Particularly, \RMOEA{} improved state-of-the-art algorithms with problems of three objectives (Figure \ref{fig:Performance_time_3obj}).
%
Moreover, this algorithm showed a lightly constant improvement increasing the number of generations.
%
However, \VSDMOEA{} attained the best results in long-term executions and could improve even more increasing the time-execution.
%


\begin{figure}[t]
\centering
%\input{Graphic-Performance-Time.tex}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.eps} \\
\begin{tabular}{l}
 \includegraphics[scale=0.6]{Images/Time_tikz-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.6]{Images/Time_tikz-figure1.eps}\\[0cm]%[-0.18cm]
 \includegraphics[scale=0.6]{Images/Time_tikz-figure2.eps}
\end{tabular}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure1.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure1.eps}
\caption{Performance of the \MOEAS{} considering three ranges of stopping criterion. The configurations take place with short-term (first row), middle-term (second row) and long-term (third row) executions.}\label{fig:Performance_time_2obj}
\end{figure}

\begin{figure}[t]
\centering
%\input{Graphic-Performance-Time.tex}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.eps} \\
\begin{tabular}{l}
 \includegraphics[scale=0.6]{Images/Time_tikz-figure3.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.6]{Images/Time_tikz-figure4.eps}\\[0cm]%[-0.18cm]
 \includegraphics[scale=0.6]{Images/Time_tikz-figure5.eps}
\end{tabular}
\caption{Performance of the \MOEAS{} considering three ranges of stopping criterion. The configurations take place with short-term (first row), middle-term (second row) and long-term (third row) executions.}\label{fig:Performance_time_3obj}
\end{figure}


\subsection{Analysis of the Initial Threshold Value}

Avoidance of premature convergence and stagnation in long-term executions is a difficult task mainly in multi-objective problems since that --depending of the problem-- the objective space implicitly involves a relation of diversity in the decision variable space.
%
For this reason, a potential strategy to mitigate those drawbacks is to lead the algorithm through different diversity stages and taking into account the stopping criterion to stimulate an appropriate balance between exploration and exploitation.
%
Nevertheless, the latter strategy, which is Incorporated in \VSDMOEA{}, requires an initial parameter, which represents the initial diversity induced in the algorithm, better known as the initial threshold value ($D_I$).
%
Accordingly, this initial threshold value is decreasing as the time elapses.
%
In order, to have a better insight about the effect raised of inducing several initial diversity stages, \VSDMOEA{} is tested with several initial threshold values and in long-term executions ($250,000$ generations).
%
Particularly, this parameter is computed as a fraction of the main normalized diagonal, which belongs to the unitary hyper-cube, the portions considered are $D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\}$.
%
In Figure \ref{fig:Initial-distance-factor} is shown the general normalized mean of the \HV{} for each configuration with two an three objectives.
%
Specifically, setting $D_I=0.0$ implies that the diversity is not promoted resulting in a similar behavior as the dominance-based algorithm.
%
In spite of this setting, \VSDMOEA{} attained better \HV{} values with all the settings than the state-of-the-art algorithms, in fact the lowest values were attained without inducing diversity, such values were $0.912$ and $0.893$ for two and three objectives respectively.
%
Especially, the maximum benefit achieved of inducing diversity is found with an initial threshold value of $DI=0.4$ with two and three objectives.
%
In addition, the behavior of setting several initial threshold value is quite similar with two and three objectives.
%
Therefore, inducing diversity and taking into account the elapses generations can be useful mainly for middle-term and long-term executions.

\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Initial-Distance_tikz-figure0.pdf} \\
\includegraphics[]{Images/Graphic-Initial-Distance_tikz-figure0.eps} \\
%\input{Graphic-Initial-Distance.tex}
\caption{Mean of \HV{} values taking into account all instances with several initial threshold values.}\label{fig:Initial-distance-factor}
\end{figure}



\input{Tables/Table_HV_2obj.tex}
\input{Tables/Table_HV_3obj.tex}
%\input{Tables/Table_IGDP_2obj.tex}
%\input{Tables/Table_IGDP_3obj.tex}
\input{Tables/Tests_HV_2obj.tex}
\input{Tables/Tests_HV_3obj.tex}
%\input{Tables/Tests_IGDP_2obj.tex}
%\input{Tables/Tests_IGDP_3obj.tex}
