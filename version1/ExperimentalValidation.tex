This section describes the experimental validation carried out to study the performance and
to get a clear understanding of the particularities of \VSDMOEA{}.
%
Results clearly show that controlling the diversity in the variable space is a way to improve further some of the results 
obtained by the state-of-art \MOEAS{}.
%
First, some technical specifications of the benchmark problems and implemented algorithms are discussed.
%
Thereafter, a comparison of long-term executions between \VSDMOEA{} and state-of-the-art algorithms is presented.
%
Then, three additional experiments to fully validate \VSDMOEA{} are included.
%
Such analyses are designed to test the scalability in the decision variable space, the performance with different stopping criteria, 
and the behavior with different initial penalty thresholds.

This work takes into account some of the most popular benchmarks that are widely applied in the multi-objective field.
%
Such problems are the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009} configured in a 
standard way.
%
The WFG test problems were used with two and three objectives and 
were generally configured (excluding the scalability study which defines different number of variables) with $24$ parameters, where $20$ of them correspond to distance parameters and $4$ to position parameters.
%
In the DTLZ test problems, the number of decision variables was set to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7, respectively.
% 
The UF benchmark comprises seven problems with two objectives (UF1-7) and three problems with three objectives (UF8-10).
%
All of them were configured with $30$ decision variables.

The experimental validation includes three well-known state-of-the-art \MOEAS{} and \VSDMOEA{}.
%
The \MOEAS{} that are taken into account are \NSGAII{}~\cite{Joel:jMetal}, \MOEAD{}~\cite{MOEADCode}, and \RMOEA{}~\cite{R2EMOACode}, 
which can be classified as dominance-based, decomposition-based, and indicator-based, respectively.
%
In the case of \MOEAD{}, several variants have been devised.
%
The \MOEAD{} implementation that has been considered is the one that attained the first place in the Congress on Evolutionary Computation 
2009 MOP Competition~\cite{zhang2009performance}.

Given that all the considered algorithms are stochastic, each execution was repeated $35$ times with different seeds.
%
In order to compare the different schemes, the hypervolume indicator (\HV{}) is used.
%
Note that in the supplementary material, results are also compared in terms of the IGD+ metrics and conclusions are quite similar.
%
The reference point used to calculate the \HV{} is chosen to be a vector whose values are sightly larger (ten percent) than the nadir point 
as is suggested in~\cite{ishibuchi2017reference}.
%
In order to facilitate the interpretation of the attained results, the normalized \HV{} is used~\cite{li2015evolutionary}
and the value reported is computed as the ratio between the normalized \HV{} reached and the maximum attainable 
normalized \HV{}.
%
In this way, a value equal to one means a perfect approximation.
%
Note that a value equal to one is not attainable because a discrete approximation is obtained by \MOEAS{}.
%
In order to statistically compare the \HV{} ratios, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whether or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the non-parametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, and the mean and median \HV{} ratio 
obtained by $X$ are higher than the mean and median achieved by $Y$.

%
The common configuration in all the experiments was the following: the population size was fixed to $100$, and the genetic operators were the Simulated Binary Crossover (SBX) and polynomial 
mutation~\cite{Joel:SBX1994, Joel:Mutation}.
%
The crossover probability was set to $0.9$ and the crossover distribution index was set to $2$.
%
Similarly, the mutation probability and distribution index were fixed to $1/n$ and $50$, respectively.
%
The additional parameterization required by each algorithm is shown in Table~\ref{tab:Parametrization}.
%
Note that in \MOEAD{} and \RMOEA{} scalarization functions are required.
%
In both cases the Tchebycheff approach is used.
%
The procedure to generate the weight vectors differs in \MOEAD{} and \RMOEA{}.
%
\RMOEA{} was applied with $501$ and $496$ weight vectors for two and three objectives respectively~\cite{trautmann2013r2}.
%
Differently, \MOEAD{} requires the same number of weight vectors than the population size.
%
They were generated with the uniform design (UD) and the good lattice point method (GLP)~\cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres}.

\subsection{State-of-the-art \MOEAS{} against \VSDMOEA{} taking into account long-term executions}

Our first experiment was devoted to compare the performance of \VSDMOEA{} against state-of-the-art proposals in the long-term, thus the stoppin criterion was set to $250,000$ generations.
%

%
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[t]
\centering
\caption{ General parameterization taking into account for each MOEA}
\label{tab:Parametrization}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{\textbf{MOEA/D}} &Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbor size = 10, \\
 & period utility updating = 30 generations, \\ 
 & local selection probability ($\delta$) = 0.9,\\ \hline
\textbf{VSD-MOEA} & $D_I=0.4$ \\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\end{tabular}
\end{table}



\input{Tables/Table_HV_2obj.tex}
\input{Tables/Tests_HV_2obj.tex}


Tables \ref{tab:StatisticsHV_2obj} shows the attained \HV{} ratio for the benchmark functions
with two objectives.
%
Specifically, the minimum, maximum, mean and standard deviation of the \HV{} ratio is shown for each tested method and function.
%
The last row shows the results considering all the functions together.
%
In each function, the data of the method that attained the largest mean is shown in bold face.
%
Additionally, all the methods that were not statistically inferior than such a method are shown in bold face.
%
From here on, the methods shown in bold face in a given problem are refered to as the winning methods.
%
Attending to the amount of functions where each method is shown is bold-face for the cases 
with two objectives, the best methods are \VSDMOEA{} and \RMOEA{} with 11 and 8, respectively.
%
Thus, while \VSDMOEA{} is the most competitive one, its superiority does not seem impressive
attending to these numbers.
%
However, the mean \HV{} ratio attained by \VSDMOEA{} when considering all the problems simultaneously is quite larger
than the one attained by \RMOEA{}.
%
In fact, the total mean of \RMOEA{} ($0.882$), \NSGAII{} ($0.886$) and \MOEAD{} ($0.881$) are quite similar.
%
In contrast \VSDMOEA{} achieved a much higher value ($0.949$).
%
If the data is inspected carefully, it is clear that when \VSDMOEA{} loses, the difference with respect to the
best method is not really large.
%
For instance, the difference between the \HV{} ratio attained by \VSDMOEA{} and by the best method was never larger
than $0.1$.
%
However, all the other methods presented a deteriation larger than $0.1$ in several cases.
%
Particularly, it happened in $5$, $5$ and $6$ problems for \RMOEA{}, \NSGAII{} and \MOEAD{}, respectively.
%
This means that even if \VSDMOEA{} loses in some cases, its deteriotation is always small showing a much more 
robust behaviour than any other method.

\input{Tables/Table_HV_3obj.tex}
\input{Tables/Tests_HV_3obj.tex}

In order to better clarify these findings pair-wise statistical tests were done among each tested method in each
function.
%
Table~\ref{tab:Tests_HV_2obj} shows for the two-objective cases, the amount of times that each method won (column $\uparrow$),
lost (column $\downarrow$) and tied (column $\leftrightarrow$).
%
Additionally, for each method $M$ we calculated the sum of the differences between the mean \HV{} ratio attained by the best method (the ones with largest mean)
and the method $M$, for each problem where, statistically, $M$ lost against the best method.
%
This value is shown in the Deterioration column.
%
The calculated data confirms that the number of wins is relatively close in \VSDMOEA{} and \RMOEA{}, but the total deterioration is quite lower in the case of \VSDMOEA{}.


Tables~\ref{tab:StatisticsHV_3obj} and \ref{tab:Tests_HV_3obj} shows the same information for the problems with three objectives.
%
In this case, the superiority of \VSDMOEA{} is even clearer.
%
Taking into account the mean of all functions, \VSDMOEA{} attained again a much larger mean \HV{} ratio than the other methods.
%
Particularly, \VSDMOEA{} attained the value $0.918$, whereas the second ranked algorithm (\RMOEA{}) attained the value $0.855$.
%
Once again, the difference between the \HV{} ratio attained by \VSDMOEA{} and by the best method was never larger
than $0.1$.
%
However, all the other methods presented a deteriation larger than $0.1$ in several cases.
%
Particularly, it happened in $5$, $6$ and $6$ problems for \RMOEA{}, \NSGAII{} and \MOEAD{}, respectively.
%
Moreover, in this case, \VSDMOEA{} is much superior than the other methods not only in terms of total deterioration but also
in terms of total wins and losses  (see Table~\ref{tab:Tests_HV_2obj} and data shown in bold face).
%
\VSDMOEA{} was in the group of the winning methods in 17 out of 19 functions, whereas the second best ranked algorithm (\RMOEA{})
belonged to the group of winning methods only in 3 functions.

\subsection{Decision Variable Scalability Analysis}

In order to study the scalability of \VSDMOEA{} in terms of the number of decision variables, all the already described algorithms were tested with
the same benchmark functions but considering $50$, $100$, and $250$ variables.
%
Given that the WFG problems require an especific configuration through different number of variables, the configuration was taken as follows.
%
The position parameters $k$ and distance parameters $l$ were set taking into consideration the formulas $k=\lfloor4/24 \rfloor \times n$ and $l=\lfloor 20/24 \rfloor \times n$, respectively.
%
Since increasing the number of variables highly increases the required computing time, this study takes into account middle-term executions, thus the stopping criterion was set to $25,000$ generations.
%
Figures \ref{fig:variable-decision-scalability-2obj} and \ref{fig:variable-decision-scalability-3obj} shows the mean \HV{} ratio for the four tested algorithms,
considering the problems with two and three objectives, respectively.
%
As expected, the \HV{} ratio decrease as the number of variables increases.
%
In the two-objective case, the deterioration is similar in every algorithm, so the superiority of \VSDMOEA{} is clear regardless of the amount of decision
variables.
%
Differently, in the three-objective case, the deterioration of \VSDMOEA{} is larger than the one of \RMOEA{} and \MOEAD{}.
%
In fact, when considering $250$ variables, the performance of \VSDMOEA{} is just slightly superior than the one of \RMOEA{}.


%In problems of three objectives, the \VSDMOEA{} performance seems to be more affected increasing the number of variables in comparison to the weight-vector based algorithms.
%
%This might by caused for several reasons, perhaps two of the most important are the stopping criterion which might not be enough to attain an adequately convergence and the distance metric taken into consideration for the management of diversity.
%
%The latter is popularly known as \textit{The Curse of Dimensionality} \cite{trunk1979problem, beyer1999nearest}, meaning that under certain broad conditions, as dimensionality is increased, the distance to the nearest neighbor tends to be the same to the farthest neighbor.
%
%In other words, the contrast in distances to different data points becomes no-existent.


\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Scalability-2obj_tikz-figure0.pdf}
\includegraphics[scale=0.85]{Images/Graphic-Scalability-2obj_tikz-figure0.eps}
%\input{Graphic-Scalability-2obj.tex}
\caption{Mean of the \HV{} ratio of 35 runs considering the two-objective problems}\label{fig:variable-decision-scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Scalability-3obj_tikz-figure0.pdf}
\includegraphics[scale=0.85]{Images/Graphic-Scalability-3obj_tikz-figure0.eps}
%\input{Graphic-Scalability-3obj.tex}
\caption{Mean of the \HV{} ratio of 35 runs considering the three-objective problems} \label{fig:variable-decision-scalability-3obj}
\end{figure}

In order to better understand this behaviour, we selected the WFG1 to WFG7 problems.
%
WFG problems divide the decision variables in two kinds of parameters: the distance parameters and the position parameters.
%
Note that, a parameter $i$ is a distance parameter when for all $\vec{\mathbf{x}}$, modifying $x_i$ results in a new solution 
that dominates $\vec{\mathbf{x}}$, is equivalent to $\vec{\mathbf{x}}$, or is dominated by $\vec{\mathbf{x}}$.
%
However, if $i$ is a position parameter, modifying $x_i$ in $\vec{\mathbf{x}}$ always results in a vector that is incomparable or 
equivalent to $\vec{\mathbf{x}}$~\cite{huband2005scalable}.
%
Additionally, note that we selected the WFG1-WFG7 problems because their distance parameters values associated to all Pareto optimal solutions 
have exactly the same values:
%
%This values is shown as follows:
\begin{equation}
   x_{i=k+1:n} = 2i \times 0.35
\end{equation}
%
This is really important because it has been shown that for some cases, state-of-the-art
\MOEAS{} provoke a quick convergence in \textit{distance parameters}, resulting in an effect that is similar to premature convergence
in the single-objective case~\cite{Joel:GDE3_CEC09}.

\begin{figure}[t]
\centering
%\input{Graphic-Diversity_2obj.tex}
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure0.pdf} \\
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure0.eps} \\[0.2cm]
%\includegraphics[]{Images/Graphic-Diversity_2obj_tikz-figure1.pdf}
\includegraphics[scale=0.85]{Images/Graphic-Diversity_2obj_tikz-figure1.eps}
\caption{Evolution of ADI for the problems WFG1-WFG7 with two objectives}\label{fig:Diversity_2obj}
\end{figure}

For each algorithm, we calculated the avarege Euclidean distance among individuals (ADI) in the population by considering only 
the distance parameters.
%
Figures \ref{fig:Diversity_2obj} and \ref{fig:Diversity_3obj} shows the ADI evolution for the two-objective and three-objective problems.
%
In order to not sature this Figures, only the information of \VSDMOEA{} and \RMOEA{} with 50, 100 and 250 decision variables is shown.
%
The first evident issue is that \VSDMOEA{} converges much slower than \RMOEA{}.
%
In this way, the difference between the diversity maintained in the first generation and the one maintained after 10\% of the execution,
is much larger in \RMOEA{} than in \VSDMOEA{}.
%
In the case of \VSDMOEA{}, the decrease in ADI is quite linear until the 50\% of the execution.
%
This is due to the way in which the threshold distance value ($D_t$) is calculated.
%
Additionally, when inspecting more closely the data, some other important aspects must be discussed. 
%
In the two-objective case, increasing the number of variables provokes a slight increase on the diversity in \RMOEA{}.
%
However, the amount of diversity is low even when using 250 variables, meaning that incorporating mechanisms to increase diversity --- as it is done in \VSDMOEA{} ---
is really helpful.
%
Differently, in the three-objective case, the amount of diversity in \RMOEA{} is not so low.
%
Moreover, increasing the number of decision variables, provokes an important increase in the attained ADI, meaning that in this case,
fast convergence is not a so important issue.
%
These results show that, as the number of objectives and variables increases, \MOEAS{} tend to maintain a higher variable space diversity
in an implicity way, meaning that explicitly controlling the variable space diversity is probably not so important.
%
Note that the behaviour of \NSGAII{} and \MOEAD{} in terms of the ADI evolution is similar to the one analyzed for \RMOEA{}.

Finally, we would like to note that we selected some specific problems to perform long-term executions with 250 distance variables.
%
\VSDMOEA{} could improve further the results when using long-term executions, while the other state-of-the-art algorithms dit not attain
important improvements.
%
This probably means that as the technology evolves and longer executions (more generations) can be performed in admisible times,
the incorporation of explicit control of diversity will be even more important.
%
Note that this also happens in the single-objective case, where benefits of explicit control of diversity appears only when using executions of
several weeks when dealing with large instances of the Traveling Salesman Problem~\cite{segura2015novel}.
%






%
%

\begin{figure}[t]
\centering
%\input{Graphic-Diversity_3obj.tex}
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure0.pdf} \\
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure0.eps} \\[0.2cm]
%\includegraphics[]{Images/Graphic-Diversity_3obj_tikz-figure1.pdf}
\includegraphics[scale=0.85]{Images/Graphic-Diversity_3obj_tikz-figure1.eps}
\caption{Evolution of ADI for the problems WFG1-WFG7 with three objectives}\label{fig:Diversity_3obj}
\end{figure}
%\begin{figure}[t]
%\centering
%\input{Graphic-Diversity_WFG6.tex}
%\label{fig:Diversity_WFG6}
%\end{figure}

\subsection{Stopping criteria and Diversity}

As previously discussed, \EAS{} with explicit control of diversity are usually more useful in long-term executions.
%
Since in our first experiment we selected a quite large stopping criterion, reader might consider that \VSDMOEA{} is only
useful in really long-term executions.
%
However, this is not the case.
%
This section is devoted to analyze the performance of \VSDMOEA{} and state-of-the-art algorithms with several stopping criteria, 
i.e. maximum number of generations.
%
Three different ranges of stopping criterion were explored.
%
Each range was split in ten intervals equally distributed and experiments with each different number of generations were run.
%
Note that state-of-the-art algorithms can be executed just one time (with $250,000$ generations) by saving the intermediate results.
%
However, \VSDMOEA{} takes decisions that depend on the stopping criteria, so independent executions were required for each stopping criterion.
%
The ranges considered were $[250, 2500]$, $[2500, 25000]$ and $[25000, 250000]$.
%
These ranges are referred to as short-term, middle-term and long-term executions, respectively.

Figures \ref{fig:Performance_time_2obj} and \ref{fig:Performance_time_3obj} show the mean \HV{} ratio attained with each \MOEA{} with two and three objectives respectively.
%
To calculate this mean ratio, all the problems are considered.
%
Each figure is divided in three graphics corresponding to short-term, middle-term and long-term.
%
In the two-objective case, for the shortest executions \VSDMOEA{} is not very competitive.
%
In the range $[250, 750]$ presents the worst performance, meaning that for really short-term executions,
explicitly promoting additional diversity is not helpful.
%
In the case of using $1,000$ generations, the attained \HV{} ratio is similar than the one attained by other methods.
%
Finally, when using more than $1,000$ generations, the \HV{} ratio attained by \VSDMOEA{} is much larger than the one
attained by other methods.
%
It is noticeable that \VSDMOEA{} is the only method that really takes advantages of using long-term executions,
with the remaining methods just showing a slight improvement.
%
In the three-objective case, \VSDMOEA{} attains a lower \HV{} ratio than \RMOEA{} and \MOEAD{} in short-term executions,
but as more generations are granted, the differences decrease.
%
In this case, when $5,000$ generations are evolved, the performance of \VSDMOEA{} is similar to the one of \RMOEA{}.
%
Finally, as in the two-objective case, with more generations the differences between \VSDMOEA{} and the remaining
algorithms increase in favor of \VSDMOEA{}.
%
Thus, while the most important benefits arise in long-term executions, practitioners can benefit from the use
of \VSDMOEA{} even in shorter executions.


\begin{figure}[t]
\centering
%\input{Graphic-Performance-Time.tex}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.eps} \\
\begin{tabular}{l}
 \includegraphics[scale=0.6]{Images/Time_tikz-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.6]{Images/Time_tikz-figure1.eps}\\[0cm]%[-0.18cm]
 \includegraphics[scale=0.6]{Images/Time_tikz-figure2.eps}
\end{tabular}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure1.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure1.eps}
\caption{Performance of the \MOEAS{} considering three ranges of stopping criterion. The configurations take place with short-term (first row), middle-term (second row) and long-term (third row) executions.}\label{fig:Performance_time_2obj}
\end{figure}



\subsection{Analysis of the Initial Threshold Value}

One of the disadvantages of including an strategy to control the diversity is that this is usally done at the cost of
incorporating additional parameters in the designed \EA{}.
%
In the case of \VSDMOEA{}, the initial threshold value ($D_I$) must be set.
%
Note that in all the previous experiments $D_I = 0.4$ was used.
%
This value was selected in base of some preliminary experiments.
%
This section is devoted to analyze the performance of \VSDMOEA{} when using different $D_I$ values and taking into account long-term executions ($250,000$ generations).
%
Note that, since normalized distances are used, the maximum difference that can appear is $1$.
%
Additionally, note that when $D_I$ is set to 0, no individual is penalized in base of its diversity contribution,
so \VSDMOEA{} would behave as a more traditional \MOEA{}.
%
As a result, the values $D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\}$ were tested.
%
As in previous experiments, the whole set of benchmark problems were used and
the stopping criterion was set to $250,000$ generations.

Figure \ref{fig:Initial-distance-factor} shows the mean \HV{} ratio attained both for the two-objective and three-objective case.
%
Note that even when $D_I$ is set to $0$, \VSDMOEA{} attained better \HV{} ratios than other state-of-the-art algorithms (see Tables~\ref{tab:StatisticsHV_2obj} and \ref{tab:StatisticsHV_3obj}).
%
Particularly, such values were $0.912$ and $0.893$ for two and three objectives, respectively.
%
This means that the novel density estimator put forth in this paper is really helpful.
%
However, the increase in performance when using other $D_I$ values is clear.
%
The obtained \HV{} ratio quickly increases as larger $D_I$ values up to $0.4$ are used.
%
Then, with values in the range $[0.5, 0.9]$ the performance decreases slightly.
%
There is a large range of values with a really good performance, meaning that 
the behaviour of \VSDMOEA{} is quite robust.
%
Thus, properly setting this parameter is not a complex task.
%
\begin{figure}[t]
\centering
%\input{Graphic-Performance-Time.tex}
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.pdf} \\
%\includegraphics[angle=90,origin=c]{Images/Graphic-Performance-Time_tikz-figure0.eps} \\
\begin{tabular}{l}
 \includegraphics[scale=0.6]{Images/Time_tikz-figure3.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.6]{Images/Time_tikz-figure4.eps}\\[0cm]%[-0.18cm]
 \includegraphics[scale=0.6]{Images/Time_tikz-figure5.eps}
\end{tabular}
\caption{Performance of the \MOEAS{} considering three ranges of stopping criterion. The configurations take place with short-term (first row), middle-term (second row) and long-term (third row) executions.}\label{fig:Performance_time_3obj}
\end{figure}

\begin{figure}[t]
\centering
%\includegraphics[]{Images/Graphic-Initial-Distance_tikz-figure0.pdf} \\
\includegraphics[scale=0.85]{Images/Graphic-Initial-Distance_tikz-figure0.eps} \\
%\input{Graphic-Initial-Distance.tex}
\caption{Mean of \HV{} values taking into account all problems with several initial threshold values}\label{fig:Initial-distance-factor}
\end{figure}



%\input{Tables/Table_IGDP_2obj.tex}
%\input{Tables/Table_IGDP_3obj.tex}
%\input{Tables/Tests_IGDP_2obj.tex}
%\input{Tables/Tests_IGDP_3obj.tex}
