In this section the experimental validation is carried out, showing that controlling the diversity in the variable space is a way to improve further some of the results obtained by state-of-art-MOEAs.
%
At the beginning, several technical specifications taken into account in our comparison outline are explained.
%
Therafter, to have a broad perception of the \VSDMOEA{} some scenaries are analyzed.
%
Between them an analyzes driven to probe the scalability in the decision variable space is taken into account.
%
This analyzes is narrowed through some specific and well known problems.
%
In the same line, with the intention to have a better understanding of the critial parameter that induces the initial amount of diversity is taken into account.
%
This is carried out through several settings and with all the test-problems.
%
Finally, since that the mechanism imposed in our proposal, which avoid the premature convergence, highly depends on the elapsed time, we reported the benefits of our proposal considering both short, and long term executions.
%
The latter experiments shows that the \VSDMOEA{} has a decent performance in short-term executions too.
%

% which belong to jMetalcpp~\cite{Joel:JMETAL} framework.
%
To validate the proposed MOEA in this work are considered some of the most popular benchmark in the multi-objective field.
%
Particularly, the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009} test problems have been used for our purpose. 
%
%Through the literature several crossover operators have been proposed in MOEAs~\cite{Joel:ParentMeanCentricSelfAdaptation},  
%a popular operator is the Simulated Binary Crossover (SBX).4\cite{Joel:SBX1994}%, Joel:TAXONOMY_CROSSOVER, Joel:Kalyanmoy}
Additionally, our experimental validation includes the \VSDMOEA{}, as well as three well-known state-of-the-art algorithms.
%
Given that all of them are stochastic algorithms, each execution was repeated $35$ times with different seeds.
%
The common configuration in all of them was the following: the stopping criterion was set to $250,000$ generations, the population size was fixed to $100$, the WFG test problems were configured with two and three objectives, which are setted to $24$ parameters, where $20$ of them are distance parameters, and $4$ are position parameters.
%
Additinally, in the DTLZ test instances, the number of decision variables is setted to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7 respectively, as is suggested by the authors \cite{Joel:DTLZ}.  
% 
The UF benchmark is composed of ten test instances, which is categorized in two groups that are based in the number of objetive functions to solve, thus the first seven consists of two objectives, and the reaming of three, where the number of decision variables taken into account in each one is $n=30$.
%
In general, the crossover and mutation operators are the Simulated Binary Crossover (SBX), and polynomial~\cite{Joel:SBX1994, Joel:Mutation}, which probabilities are setted to $0.9$ and $1/n$ respectively.
%
Also, the crossover and mutation distribution indexes were assigned to $20$ and $50$ respectively.
%
The extra-parameterization of each algorithm is showed in the table~\ref{tab:Parametrization}.
%
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[t]
\centering
\caption{Parameterization of each MOEA considered}
\label{tab:Parametrization}
\begin{tabular}{|c|c|}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{\textbf{MOEA/D}} &Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbour size = 10, \\
 & period utility updating = 30 generations \\ 
 & probability local selection ($\delta$) = 0.9,\\ \hline
\textbf{VSD-MOEA} & $D_I=\sqrt{n}*0.25$ \\ \hline
\end{tabular}
\end{table}

The MOEA/D and R2-EMOA are 

employes utility functions the algorithms \MOEAD{} and R2-EMOA require a set of vectors uniformly scattered on the unit-simplex.
%


 therefore the number of vectors generated increases nonlinearly with the number of objectives.
%
Consequently, is applied the method proposed in \cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres} where the uniform design (UD) \cite{Joel:Uniform_Design} and good lattice point (glp) are combined.
%
Thus the number weight of vectors is not affected by the number of objectives.

In addition, our experimental analysis has been carry out with the hypervolume indicator, since the WFG benchmark variate the Pareto front shape with different distance parameters \cite{Joel:ScalabilityStudy}.
%

In this work the reference points are chosen to be a vector with values slightly larger than the nadir point, also for complex problems the reference point is considered as nadir point plus the unity.
%
Therefore the reference points implemented in the hypervolume indicator are showed in the table \ref{tab:ReferencePoints} as used in \cite{Joel:Kuhn_Munkres, Joel:OperatorAHX}.

\begin{table}[t]
\centering
\caption{References points for the HV indicator}
\label{tab:ReferencePoints}
\begin{tabular}{cc}
\hline
\textbf{Instances} & \textbf{Reference Point} \\ \hline
WFG1-WFG9 & $[2.1, ...,2m+0.1]$ \\
DTLZ 1, 2, 4 & $[1.1, ..., 1.1]$ \\
DTLZ 3, 5, 6 & $[3, ..., 3]$ \\
DTLZ7 & $[1.1, ..., 1.1, 2m]$ \\
UF 1-10 & $[2, ..., 2]$ \\ \hline
\end{tabular}
\end{table}
%
In order to statistically compare the hypervolume results, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whatever or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the nonparametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, if the mean and median obtained by $X$ are higher than the mean and median achieved by $Y$.

%

In the tables \ref{tab:StatisticsHV_2obj}, \ref{tab:StatisticsHV_3obj} are showed the hypervolume statistics with two an three objectives respectively.
%
The column \textit{Diff} indicate how far is the best HV mean from each algorithm, this field is computed as the difference between the mean of the each algorithm and the best mean.
%
Consequently, the best algorithm in each instance has assigned a zero.
%

Considering two objectives the GDE3 provides the best results, however the VSD-MOEA is very close to the GDE3 as is showed in the \textit{Diff} columns.
%
It is important to highlight that the DTLZ test suites have the next weaknesses \cite{Joel:CEC2009}.
The global optimum lies in the center or bounds, all are separable and the global optimum has the same parameter values for different dimensions.
%
Particularly the DTLZ5 and DTLZ6 are easy for the GDE3, since the global optimal are located in the low bound, thus if the differential operators locate a solution outside of bounds, the repair procedure could move the point among the optimal.

%
Additionally, the GDE3 get worse according increases the number of objectives, even more the \textit{Diff} results are in average high, except for the DTLZ5 and DTLZ6 where the optimal set are located along the bounds.
%
Despite the fact that the VSD-MOEA does not have a repair procedure because it implements genetic operators, the results are fairly stable.
%
Also improves the hypervolume with three objectives, hence can be considered a robust algorithm, in fact considering more objectives it provides better results than the dominance-based algorithms\footnote{Experimentally with ten objectives the algorithm is best than dominance-based MOEAs.}.
%
A remarkable characteristic that can be appreciated in two and three objectives is that our  proposal provide the best results in the most difficult problems as are dependence, multi-modal and deceptiveness.

%
On average the VSD-EMOA has lower \textit{Diff} value than the rest of algorithms, therefore considering all best mean of each instance, the VSD-EMOA is not too far from the best means.
%
Even more, the min and max averages are better than the min and max of the state-of-art algorithms.
%

The effective test showed in the tables \ref{tab:Effective_Test_2obj}, \ref{tab:Effective_Test_3obj} are conformed by two an three objectives respectively,  these metrics qualify the superiority of each algorithm with the rest through pair comparisons.
%
Thus, an algorithm \textbf{A} is compared with algorithm \textbf{B}, if \textbf{A} wins, the difference with \textbf{B} is accumulated in wins $\uparrow$ of the algorithm \textbf{A}, the same process is for the algorithm \textbf{B} but it is accumulated in the lost field $\downarrow$.
%
The column \textit{Score} is conformed by the difference between the win and lost values, therefore a high positive score indicate the superiority of the algorithm.
%

In addition, our proposal has low negative scores in the DTLZ6 and WFG6 with two objectives, it might occurs because these instances are not a problem to long term executions, therefore they are totally defined by the crowding procedure.
%
However, the negative scores in VSD-MOEA are not highly significant.
%
Additionally, considering three objectives, the VSD-MOEA provides the best and positive scores.
%
In general our proposal has the best scores in difficult instances as are the UF and some WFG problems.

\subsection{Decision Variable Scalability Experiments}

The scalability of each MOEA is also evaluated respect with the number of decision variables \cite{Joel:ScalabilityStudy}. 
%
The figures \ref{fig:Scalability_Study_HV_1}, \ref{fig:Scalability_Study_HV_2} show the hypervolume performance of 30, 100, 250 and 500 variables respectively.
%
Particularly,  the scalability study was realized in DTLZ4, UF5 with two objectives and DTLZ4, UF10 with three objectives.
%
In some instances the GDE3 degrades relatively fast according increases the number of decision variables as is showed in UF5, UF10 and DTLZ4 with three objectives.
%
Also, the GDE3 show a non-stable performance with the parameter configurations, as is explained by J. Lampinen et al.\cite{Joel:GDE3_CEC09}, where they indicate that a high value for CR might lead to premature convergence with respect to one objective compared to another.

%
Specifically, the instance UF10 with GDE3 has an increment of HV for 100 variables, this irregularity is related with diversity issues \cite{Joel:GDE3_CEC09}
%
On the other hand the VSD-MOEA is enough stable, also it provides the best HV values.
%
It is interesting that the MOEA/D and MOMBI-II required an extra-parametrization, hence the stability could be compromised.

%
The 50\% attainment surfaces WFG2, WFG8 and DTLZ7 instances are showed in the figure \ref{fig:Attainment_Surfaces}.
%
The analyses shows that our proposal provide solutions approximated to the Pareto front.
%
Although the GDE3 approximate the WFG2 and DTLZ7, this this algorithm is far in some regions of the Pareto front with the WFG8 instance. 

\begin{figure}[t]
\centering
\input{Graphic-Scalability-2obj.tex}
\label{fig:variable-decision-scalability-2obj}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Scalability-3obj.tex}
\label{fig:variable-decision-scalability-3obj}
\end{figure}



\subsection{Analyzes of the Intial Factor Distance}

\begin{figure}[t]
\centering
\input{Graphic-Initial-Distance.tex}
\label{fig:Initial-distance-factor}
\end{figure}

\subsection{Convergence of the Diversity of WFG1}
\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG1.tex}
\label{fig:Diversity_WFG1}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG5.tex}
\label{fig:Diversity_WFG5}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG6.tex}
\label{fig:Diversity_WFG6}
\end{figure}


\subsection{Improving Dependece on the Execution}


\begin{figure}[t]
\centering
\input{Graphic-Performance-Time.tex}
\label{fig:Performance_time}
\end{figure}



\input{Tables/Table_HV_2obj.tex}
\input{Tables/Table_HV_3obj.tex}
\input{Tables/Table_IGDP_2obj.tex}
\input{Tables/Table_IGDP_3obj.tex}
\input{Tables/Tests_HV_2obj.tex}
\input{Tables/Tests_HV_3obj.tex}
\input{Tables/Tests_IGDP_2obj.tex}
\input{Tables/Tests_IGDP_3obj.tex}
