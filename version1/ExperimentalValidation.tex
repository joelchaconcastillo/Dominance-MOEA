In this section the experimental validation is carried out, showing that controlling the diversity in the variable space is a way to improve further some of the results obtained by the state-of-art-MOEAs.
%
The analysis carried out in this section is carefully designed to get a clear understanding of the particularities of \VSDMOEA{}.
%
First, several technical specifications of the implemented agorithms, and test problems are described.
%
Thereafter, a core comparison between \VSDMOEA{} and the state-of-the-art is presented.
%
Additionally, to have a broad perception of the \VSDMOEA{} three extra experiments are driven.
%
Such analyses are aimed to test the scalability in the decision variable space, the diversity parameter required by \VSDMOEA{}, and several stopping criterion settings.
%
Particularly, the latter is probed with several terms-execution, i.e. from short-term to long-term executions.


%
%Firstly, several technical specifications taken into account in our comparison outline are explained.
%
%Thereafter, to have a broad perception of the \VSDMOEA{} some experiments are driven.
%
%Between them an analyzes which is designed to test the scalability in the decision variable space of each \MOEA{}.
%
%This analyzes is narrowed through some specific and well known problems.
%
%In the same line, with the intention to have a better understanding of the critical parameter that induces the initial amount of diversity is taken into account.
%
%This is carried out through several settings and with all the test-problems.
%
%Finally, since that the mechanism imposed in our proposal, which avoid the premature convergence, highly depends on the elapsed time, we reported the benefits of it considering short-term and long-term executions.
%
%The latter experiments shows that the \VSDMOEA{} has a decent performance in midterm executions.
%

This work is validated through some of the most popular bechmarks in the multi-objective field.
%
Such problems are the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009}.
%
Furthermore, the experimental validation includes three well-known state-of-the-art MOEAs and the \VSDMOEA{}.
%
The MOEAs taken into account are the \NSGAII{}~\cite{Joel:jMetal} , the \MOEAD{}~\cite{MOEADCode}, and the \RMOEA{}~\cite{R2EMOACode}, that can be classified as based-dominance, based-decomposition, and based-indicators respectively.
%
Particularly, the \MOEAD{} implementation belongs to the first place in the ``Congress on Evolutionary Computation 2009'' (CEC) \cite{zhang2009performance}.
%
Given that all the considered algorithms are stochastic, each execution was repeated $35$ times with different seeds.
%
The common configuration in all the executions was the following: the stopping criterion was set to $250,000$ generations, the population size was fixed to $100$, the WFG test problems were configured with two and three objectives, which are set to $24$ parameters, where $20$ of them are distance parameters, and $4$ are position parameters.
%
Additionally, in the DTLZ test instances, the number of decision variables is set to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7 respectively, as is suggested by the authors \cite{Joel:DTLZ}.  
% 
The UF benchmark is conformed by seven problems with two objectives (UF1-7) and three problems with three objectives (UF8-10), such problems are set with $30$ decision variables.
%
The operators employed on all the MOEAs are the Simulatied Binary Crossover (SBX), and the polynomial mutation~\cite{Joel:SBX1994, Joel:Mutation}.
%
In the crossover the probability and distribution index are set to $0.9$ and $2$ respectively.
%
Similarly, the mutation probability and distribution index are set to $1/n$ and $50$ respectively.
%
%
%The crossover and mutation probabilities are set to $0.9$ and $1/n$ respectively.
%
%In general, the crossover and mutation operators are the Simulated Binary Crossover (SBX), and polynomial~\cite{Joel:SBX1994, Joel:Mutation}, which probabilities are set to $0.9$ and $1/n$ respectively.
%
%Also, the crossover and mutation distribution indexes were assigned to $2$ and $50$ respectively.
%
In addition, the extra-parameterization of each algorithm is shown in the Table~\ref{tab:Parametrization}.


%In order, to validate the proposed MOEA, in this work are considered some of the most popular benchmark in the multi-objective field.
%
%Particularly, the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009} test problems have been used for our purpose. 
%
%Through the literature several crossover operators have been proposed in MOEAs~\cite{Joel:ParentMeanCentricSelfAdaptation},  
%a popular operator is the Simulated Binary Crossover (SBX).4\cite{Joel:SBX1994}%, Joel:TAXONOMY_CROSSOVER, Joel:Kalyanmoy}
%Additionally, our experimental validation includes the \VSDMOEA{}, as well as three well-known state-of-the-art algorithms.
%
%In addition, out experimental validation includes the \VSDMOEA{}, as well three well-known state-of-the-art MOEAs.
%
%There are the \NSGAII{}~\cite{Joel:jMetal} , the \MOEAD{}~\cite{MOEADCode}, and the \RMOEA{}~\cite{R2EMOACode}, that can be classified as based-dominance, based-decomposition, and based-indicators respectively.
%
%The \MOEAD{} implementation taken into account belongs to the first place in the ``Congress on Evolutionary Computation 2009'' (CEC) \cite{zhang2009performance}.
%
%

%
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[t]
\centering
\caption{Parameterization of each MOEA considered}
\label{tab:Parametrization}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{\textbf{MOEA/D}} &Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbor size = 10, \\
 & period utility updating = 30 generations \\ 
 & probability local selection ($\delta$) = 0.9,\\ \hline
\textbf{VSD-MOEA} & $D_I=0.4$ \\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\end{tabular}
\end{table}


%

In addition, \MOEAD{} and \RMOEA{} are configured with the Tchebycheff approach as utility function.
%
According to their implementations each algorithm takes into account different weight vectors.
%
Particularly, \RMOEA{} can be configured with a different quatity of weight vectors than the population size.
%
Thus, it employs $501$ and $496$ weight vectors for two and three objectives respectively.
%
In contrast, \MOEAD{} requires the same number of weight vectors than the population size.
%
As a result, to have the same population size in all the algorithms, the weight vectors are generated with the uniform design (UD) and the good lattice point method (GLP)~\cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres}.

%Despite the fact that the \MOEAD{}, and \RMOEA{} can be employed with the same utility function --in this case the Tchebycheff function-- each one of them is designed through a notorious dissimilar paradigm.
%
%Thus, the weight vectors taken into consideration for each one of them were different.
%, i.e. the confias it was originally proposed by the authors. 
%
%The main reason of this, is that the \RMOEA{} can be configured with a different population size than the number of weight vectors without been significantly affected.
%
%Particularly, the \RMOEA{} employs $501$ and $496$ weight vectors for two and three objectives respectively.
%
%Contrarily, in the \MOEAD{} each weight vector is identified as a sub-problem, therefore the population should correspond to the same number of weight vectors.
%
%In addition, the weight vectors used in the \MOEAD{} should be uniformly scattered on the unit-simplex, however it can be a drawback since that the number of vectors required for this task increases non-linearly according the number of objectives.
%
%Therefore, in this version is applied the method proposed in \cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres} where the uniform design (UD) \cite{Joel:Uniform_Design} and good lattice point method (GLP) are combined.
%
%In this way, the number of weight vectors that is required by this \MOEA{} is not affected by the number of objectives.


Mainly, the experimental analyzes is carried out considering the hypervolume indicator (\HV{}).
%
The \HV{} metric measures the objective space dominated by the approximated solutions given a reference point, so the solutions dominated by the reference point are not considered.
%
Particularly, the reference point is chosen to be a vector whose values are sightly larger (ten percent) than the nadir point as is suggested in \cite{ishibuchi2017reference}.
%
Similarly that in \cite{li2015evolutionary}, and to have a fair comparison the normalized \HV{} is estimated.
%
Specifically, the \HV{} reported is computed as the ratio between the \HV{} reached by a set of solutions and the \HV{} of a set of points that belong to the Pareto Front.
%
In this way, the more approximated to the unity this metric is, the more converged are the solutions to the Pareto Front.
%



%%\begin{table}[t]
%%\centering
%%\caption{References points for the HV indicator}
%%\label{tab:ReferencePoints}
%%\begin{tabular}{cc}
%%\hline
%%\textbf{Instances} & \textbf{Reference Point} \\ \hline
%%WFG1-WFG9 & $[2.1, ...,2m+0.1]$ \\
%%DTLZ 1, 2, 4 & $[1.1, ..., 1.1]$ \\
%%DTLZ 3, 5, 6 & $[3, ..., 3]$ \\
%%DTLZ7 & $[1.1, ..., 1.1, 2m]$ \\
%%UF 1-10 & $[2, ..., 2]$ \\ \hline
%%\end{tabular}
%%\end{table}
%
In order to statistically compare the \HV{} results, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whatever or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the non-parametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, if the mean and median obtained by $X$ are higher than the mean and median achieved by $Y$.
%

In Tables \ref{tab:StatisticsHV_2obj} and \ref{tab:StatisticsHV_3obj} are shown the normalized hypervolume with two and three objectives respectively.
%
In this empirical results the \VSDMOEA{} achieved the best general mean, and its standard deviation achieved is not significantly high, meaning being quite stable to different random initialization of the population.
%
According to Table \ref{tab:StatisticsHV_2obj} the dominance-based algorithms improved the remaining MOEAs.
%
However, the general mean of \NSGAII{} (second best algorithm with $0.886$) is quite similar than \MOEAD{} ($0.881$) and \RMOEA{} ($0.882$), in contrast \VSDMOEA{} achieved a high \HV{} value ($0.951$).
%
In particular, the dominance-based algorihms gave the best values in the kind of problems with disconnected Pareto geometries (WFG2, UF5 and UF6).
%
Taking into account three objectives, \NSGAII{} is placed as the worst algorithm ($0.785$) and this might occurs by its density estimator, which has some drawbacks in the most difficult problems with three objectives (e.g. multi-frontality).
%
The second place is attained by \RMOEA{} ($0.855$), which is still quite low compared with \VSDMOEA{} ($0.916$).
%


Given that the general mean can be unsteady to atypical measurements, which is found in results with high standard deviation, in Tables \ref{tab:Tests_HV_2obj} and \ref{tab:Tests_HV_3obj} are shown the statistical tests with two and three objectives respectively.
%
Such tables incorpore the difference between the mean in each algorithm and the best mean achieved for each problem, which is tagged with ``Diff''.
%
A representative value of each column is shown in the last row, which is conformed by the sum of the enterely column.
%
The algorithm that attained more wins in the pair-wise comparison is the \VSDMOEA{} with $48$ and $52$ wins in two and three objectives respectively.
%
Besides that \VSDMOEA{} lost in several pair-wise comparisons it is enough close to the best results, it is noted with the differences obtained with the best result.
%
In fact, \VSDMOEA{} achieved $0.060$ and $0.027$ in contrast the second bests algorithms are \NSGAII{} and \RMOEA{} in two and three objectives respectively.
%
Particularly, the worst ``Diff'' value achieved by the \VSDMOEA{} is with the WFG6 test-problem ($0.045$ and $0.024$), which is uni-modal and non-separable.
%
Nevertheless, this problem was better approximated with $D_I=0.1$ whose means were of $0.913$ and $0.868$ for two and three objectives respectively.
%
Therefore, this test-problem is improved inducing less diversity at the initial stages of the execution.
%
%This problem is uni-modal and non-separable, and this might occurs since that the initial factor distance is very high.

%

%It is important to remark that the general mean can be unsteady to atypical measurements, which is found in high standar deviation results, thus very low values could affect highly the general mean.
%
%The second best \MOEA{} based in the general mean is the \RMOEA{} with $0.855$, despite that it adopts the same utility function that the \MOEAD{}, the latter is lightly lower with $0.835$, this might occurs given that the \MOEAD{} has several parameters to be tuned, and the selected configuration could be insufficient to long-term executions.
%

%From this empirical results, it is clear that the \VSDMOEA{} achieves the highest general mean \HV{} with both two and three objectives (last row).
%
%Even more, the standard deviation is the lowest in almost all the problems, therefore this \MOEA{} shows to be stable, consequently it is able to attain similar results through several runs.
%
%The best general mean considering two objectives is achieved by the \VSDMOEA{} with $0.955$.
%
%Also, the second general mean is obtained by the \NSGAII{} with $0.886$.
%
%
%However, all the state-of-the-art-\MOEAS{} achieved a general mean of $0.88$ considering two objectives, whilst the \VSDMOEA{} obtained $0.95$.
%
%Considering three objectives the performance of the \NSGAII{} is seriously affected, this might occurs since that the density estimator employed in the \NSGAII{} highly depends on the dominance-relation, thus in some problems (e.g. multi-frontal problems UF10) the solutions do not converge adequately to the Pareto front.
%
%In the same line, the \VSDMOEA{} achieved the best \HV{} values in almost all the problems, in fact such values that are higher than $0.9$ are close enough to the Pareto Front.
%
%


%In the Tables \ref{tab:Tests_HV_2obj} and \ref{tab:Tests_HV_3obj} are shown the statistical tests with two and three objectives respectively.
%%
%In the column tagged ``Diff'' is computed the difference between the mean of each algorithm and the best mean achieved.
%
%Taking into account two objectives the \VSDMOEA{} attains the best score of $52$ wins, the second best score is attained by the \RMOEA{} with $34$ wins.
%
%In spite that the \NSGAII{} achieves a better general mean, it wins less times that the remaining \MOEAS{}.
%
%Meaning that the \NSGAII{} obtains values close enough than the best \MOEA{}, this can be viewed in the last row where is computed the total sum of all the problems.
%
%Generally speaking, the best results are obtained by the \VSDMOEA{}, since that the total sum of the ``Diff'' column is $0.061$, thus when this algorithm does not achieved the best results, it obtained near solutions to the best results.
%
%Furthermore, the algorithms \RMOEA{} and \MOEAD{} achieved a similar total ``Diff'' values.
%
%
%
%In addition, a similar behavior can be seen with three objectives (Table \ref{tab:Tests_HV_3obj}), where the \VSDMOEA{} improves significantly in comparison to the state-of-the-art-MOEAs.
%
%Particularly, the most complicated problems are better solved by the \VSDMOEA{} as are UF3, UF4, UF5, and UF6 composed by two objectives, and UF9, UF10 with three objectives.
%
%The UF5 is considered as one of the most difficult problems since that the optimal Pareto front is conformed by $21$ points, also it has several sub-optimal regions where the solutions could suffer stagnation. 
%
%Nevertheless, since that it is a disconnected Pareto front, the \MOEAS{} that considers weight vectors faces several difficulties (e.g. knee regions), consequently they have more chances to stagnate.
%
%In fact in the latter problem the \NSGAII{} has a lower ``Diff'' value ($0.048$) than the \MOEAD{} and \RMOEA{} ($0.205$ and $0.122$).
%
%Diversely, the UF10 is a multi-frontal problem, this means that there exists different sub-optimal non-dominated fronts that correspond to different locally optimal values \cite{huband2006review}, this characteristic increases the difficulties of the problem as the number of objectives increases.
%
%However, the latter problem has notably converged better in \VSDMOEA{} ($0.627$) than in the remaining \MOEAS{} (second best $0.413$).
%


\subsection{Decision Variable Scalability Analysis}

In order, to study the scalability of the decision variables, and following the same guideline of validation, the algorithms were test with $50$, $100$, and $250$ variables.
%
Particularly, since that long-term executions (250000 generations) are time-consuming, this analysis is carried out with middle-term executions (25000 generations).
%
In Figures \ref{fig:variable-decision-scalability-2obj} and \ref{fig:variable-decision-scalability-3obj} are shown the normalized mean of the \HV{} results for two and three objectives respectively.
%
All the algorithms were deteriorated as the number of variables is increased.
%
In fact, the based-dominance algorithms are the best in problems of two objectives.
%
In contrast, taking into account problems of three objectives, the weight-vector based algorithms show to be enough stable according the increment of the variables in comparison to the dominance-based algorithms.
%
In addition, the weight-vector based algorithms have a similar performance increasing the number of decision variables.
%
However, \VSDMOEA{} is still the best algorithm in both two and three objectives.
% 
In problems of three objectives, \VSDMOEA{} is deteriorated with the number of variables in comparison to the weight-vector based algorithms, this might by caused for several reasons, perhaps two of the most important are the time-execution involved and the distance metric used in the magnament of diversity.
%
The latter is popularly known as \textit{The Curse of Dimensionality} \cite{trunk1979problem, beyer1999nearest}, meaning that under certain broad conditions, as dimensionality is increased, the distance to the nearest neighbor approaches the distance to the farthest neighbor.
%
In other words, the contrast in distances to different data points becomes no-existent.


%
%This might occurs for several reasons, perhaps the most important is related with the measurement employed in the variable space (Euclidean distance), this inconvenient is popularly known as \textit{The Curse of Dimensionality} \cite{trunk1979problem, beyer1999nearest}.

%

%to analyse the scalability of the decision variable space, each algorithm is evaluated through $50$, $100$ and $250$ variables.


%The scalability of each MOEA is also evaluated respect with the number of decision variables \cite{Joel:ScalabilityStudy}. 
%
%The figures \ref{fig:variable-decision-scalability-2obj} and \ref{fig:variable-decision-scalability-3obj} show the mean of \HV{} attained with $50$, $100$, $250$, $500$, and $1000$ variables respectively.
%
%The scalability study was taken into consideration with some problems conformed by easy and difficult characteristics.
%
%Particularly, the problems considered in this analyzes were the DTLZ4, UF5 which are conformed by two objectives, and DTLZ4, UF10 with three objectives.
%
%In addition, each selected problem was repeated $35$ times, thus the mean of all the \HV{} values are reported.
%
%The \VSDMOEA{} attained the best results in two objectives with both problems, however it is remarkable to notice that the \HV{} value reported by the \NSGAII{} improves as the number of decision variables is increased.
%
%Specifically, the DTLZ4 is uni-modal, and its Pareto shape is concave, also it has a polynomial bias.
%
%This interesting behavior is also showed by the \RMOEA{}, and can be explained as follows.
%
%The probability of stagnation in certain sub-optimal regions can be avoided increasing the decision variables space.
%
%It highly depends in the operators that are taken into account (in this case the SBX and polynomial mutation), thus in some circumstances the more bigger the variable decision space is, the better quality solutions are reached.
%
%This can be lightly seen in the \MOEAD{} after $250$ variables, however we believe that this \MOEA{} is highly parameter-sensitive.
%
%A differently effect is presented in the UF5, in this problem the more bigger the variable space is, the less quality solutions are obtained.
%
%Despite this the \VSDMOEA{} still attains the best \HV{} values.
%
%However, the \VSDMOEA{} is not the best \MOEA{} in all the circumstances, it can be seen considering three objectives (Figure \ref{fig:variable-decision-scalability-3obj}).
%
%Specifically, where the number of variables is increased to one thousand in both problems (DTLZ4 an d UF10) its performance is highly degraded.
%
%
%
%The remaining \MOEAS{} show a similar behavior with the DTLZ4 with two and three objectives.
%
%As previously mentioned the performance of \VSDMOEA{} is seriously deteriorated, however it is still better than the \NSGAII{}.
%
%Also, the \RMOEA{} seems to be enough stable with three objectives in the problems DTLZ4 and UF10.

\begin{figure}[t]
\centering
\input{Graphic-Scalability-2obj.tex}
\label{fig:variable-decision-scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
\input{Graphic-Scalability-3obj.tex}
\label{fig:variable-decision-scalability-3obj}
\end{figure}

%\subsection{Diversity of the \MOEAS{} Through Generations}

In order, to have a better understanding of the algorithms and following the guideline of middle-term executions, the diversity in the decision variable space is computed with some WFG problems.
%
Particularly, these problems divide the decision variables in two kinds of patameters: the distance parameters and the position parameters.
%
A parameter $x_i$ is a distance parameter when for all parameter vectors $\vec{F}(\mathbf{x})$, modifying $x_i$ in $\vec{F}(\mathbf{x})$ results in a parameter vector that dominates $\vec{F}(\mathbf{x})$, is equivalent to $\vec{F}(\mathbf{x})$, or is dominated by $\vec{F}(\mathbf{x})$.
%
However, if $x_i$ is a position parameter, modifying $x_i$ in $\vec{F}(\mathbf{x})$ always results in a vector that is incomparable or equivalent to $\vec{F}(\mathbf{x})$~\cite{huband2005scalable}.
%

%In this section we show that state-of-the-art-\MOEAS{} do not always maintain high enough diversity.
%
Particularly, the selected problems are used to show that premature convergence or stagnation appears in the set of distance parameters.
%
Consequently, the operators involved lose its exploratory strength.
%
%We select the first seven WFG problems (WFG1-7), because they have simple definition, but most MOEAs faces difficulties with them. 
%
%In addition, those problems were taken into account given that the WFG1 and WFG5 were better solved by the \VSDMOEA{}.
%
%Generally speaking, the WFG1 converged to the Pareto Front with our proposal, this since that the accuracy obtained was of $0.993$.
%
%In contrast, the WFG5 was still far away of the Pareto Front which \HV{} mean  was of $0.923$.
%
%Contrarily, the WFG6 was chosen since that the \VSDMOEA{} achieved the worst results.
%
%Whereas the WFG1 and WFG6 are uni-modal, the WFG5 is a highly deceptive problem.
%
%Moreover, the WFG1 and WFG5 are conformed by the separable properties of its objective functions.
%
We select the WFG1-WFG7 problems because their distance parameters values associated to Pareto optimal solutions have exactly the same values.
%In fact, the distance parameters values associated to Pareto optimal solutions for WFG1-WFG7 have exactly the same values in the distance parameters.
%
This values is shown as follows:
\begin{equation}
   x_{i=k+1:n} = 2i \times 0.35
\end{equation}
%
%Taking into account the stochastic behavior of \MOEAS{}, $35$ independent executions were run by each selected problem.
%
%In all of them, the stopping criterion was set to $25,000$ generations.
%
In order to analyze the diversity, the average Euclidean distance among individuals (ADI) is calculated, i.e. the mean value of all pairwise distances among individuals in the population is reported.
%
In Figures \ref{fig:Diversity_2obj} and \ref{fig:Diversity_3obj} are shown the evolution of diverstiy with two and three objectives.
%
Concretely, each figure shows the diversity maintained with the position parameters and the distance parameters.
%
The diversity is calculated for $50$, $100$, and $250$ variables with all the algorithms.
%
Principally, state-of-the-art algorithms converges to certain promising regions in distance parameters after the $10\%$ of total time-execution.
%
Nevertheless, in relation with state-of-the-art, the diversity in position parameters increases as the time elapses, meaning that the remaining $90\%$ is devoted to improve the quality in the objective space.
%
Therefore, the algorithms tend to stagnate after that the distance parameters converges to promising regions (it could be non-optimal region).
%
In contrast, \VSDMOEA{} keeps diverse solutions in both kind of parameters until the $50\%$ of the time elapsed.
%


The diversity maintained in problems of three objectives is larger than with problems of two objectives, this might occurs since that the quantity of prominent solutions increases meaninfully between two and three objectives.
%
Therefore, there is present an implicit relation of diversity between the number of objectives and the decision variables space, in this situation three objectives keeps implictly more diversity than two objectives.
%
However, this implicit diversity maintained is not enough to avoid stagnation in several problems.
%
Thus, considering long-term executions in state-of-the-art algorithms could not improve meaningfully.
%
In contrast, \VSDMOEA{} could improve even more with long-term executions, since that it keeps diversity at several stages.
%
In general, as the number of variables is increased, the convergence in the distance parameters is even more slow, therefore to have quality solutions is required a greater time-execution, for example with $250$ variables the distance parameters are still moving.
%

%
%In the Figures \ref{fig:Diversity_WFG1}, \ref{fig:Diversity_WFG5}, and \ref{fig:Diversity_WFG6} are showed the evolution of diversity of the WFG1, WFG5, and WFG6 respectively.
%
%In those figures each \MOEA{} is showed by dashed and solid lines that represents two and three objectives respectively.
%
%Particularly, the \VSDMOEA{} properly maintains diversity in both kind of parameters, while in the remaining algorithms the diversity in the distance parameters is lost after the $10\%$ (generation $2500$) of total generations.
%
%Thus, after those \MOEAS{} converges, they are basically modifying the position parameters, so the majority of the time is improving further the diversity in the objectives space and the convergence is neglected.
%
%In fact, this diversity issue is also present in the WFG5.
%
%However, all the \MOEAS{} have a minimum lower bound of diversity in the position parameters of those selected problems.
%
%Contrastively, considering the WFG5 (Figure \ref{fig:Diversity_WFG5}) the \VSDMOEA{} does not converge at all in the distance parameters with three objectives, this might be an effect of promoting too much diversity.
%
%Besides this issue, the \VSDMOEA{} still achieves the best \HV{} values.
%
%In addition, this drawback is more notorious in the problem WFG6.
%
%In fact in two and three objectives this \MOEA{} did not converges in the distance parameters, and the position variables are still more diversified as in WFG1.


\begin{figure}[t]
\centering
\input{Graphic-Diversity_2obj.tex}
\label{fig:Diversity_2obj}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_3obj.tex}
\label{fig:Diversity_3obj}
\end{figure}


%\begin{figure}[t]
%\centering
%\input{Graphic-Diversity_WFG6.tex}
%\label{fig:Diversity_WFG6}
%\end{figure}

\subsection{Stagnation with \MOEAS{}}


This section is devoted to test the perfomance of the algorithms with several term-executions.
%
As was previously discussed, state-of-the-art algorithms might suffer of stagnation.
%
Thereforei, the solutions could converge in promising (but non-optimal) regions at the first stages of the execution and wasting a meaningfull quantity of time-execution.
%
To deal with this issue, \VSDMOEA{} maintains diversity at different stages as long as the stopping criterion is reached.
%
Accordingly, to have a better understanding of the behavour that the algorithms have with different term-executions, the mean of normalized \HV{} of all the problems for two and three objectives are computed.
%
Mainly, three ranges of stopping criterion were probed.
%
Each range was split in ten intervals, such ranges considered were $[300, 2500]$, $[2500, 25000]$ and $[25000, 250000]$ respectively.
%
In Figure \ref{fig:Performance_time} are showed the mean \HV{} values attained with each \MOEA{} with two and three objectives respectively.
%
This shows that \VSDMOEA{} atteined competitive results considering short-term executions.
%
Even more, as the time-execution is increased its performance is improved.
%
In fact after $2500$ generations the \VSDMOEA{} has a notorious improvement respect to the state-of-the-art-\MOEAS{} in both two and three objectives.
%
In problems with two objectives state-of-the-art algorithms attained quite similar \HV{} values in long-term executions (250000 generations).
%
The weight-vector based algorithms had a similar behaviour in relation with the stopping criterion.
%
Particularly, \RMOEA{} improved state-of-the-art algoriths in the problems of three objectives.
%
Moreover, this algorithm showed a lightly constant improving in relation if the stopping criterion.
%
However, \VSDMOEA{} attained the best results in long-term executions.

%
%In spite that the \VSDMOEA{} is specially designed to attain quality solutions in long-term executions.
%
%In this section is showed the performance of the \MOEAS{} modifying the criteria stop.
%
%Mainly, three ranges of criteria stop were reviewed.
%
%
%
%
%
%It can be seen that as the maximum number of generations is higher than $25000$ the remaining \MOEAS{} seems to be stagnated, specifically considering two objectives.
%
%Moreover, considering three objectives the \RMOEA{} shows improvements after $100000$ generations, however it still has lower values than the \VSDMOEA{}.
%
%In addition, taking into account three objectives the best general mean value achieved was above $0.9$, there is still possible that increasing the number of generations the \VSDMOEA{} achieves better results.
%
%However, in some circumstances, as seems to be in the case of two objectives, might not be able to achieve a better accuracy, thus an upper bound could be present.
%
%It is significant important to note how the performance of the \NSGAII{} is degraded in three objectives, differently to the \RMOEA{}, and the \MOEAD{}.
%
%Even more, the \MOEAD{} seems to be stagnated after $25000$ generations, this might occurs for the greedy selection approach that this \MOEA{} incorporates.
%
%In fact the \MOEAD{} attained better results than the \RMOEA{} in short-term executions.
%

\begin{figure}[t]
\centering
\input{Graphic-Performance-Time.tex}
\label{fig:Performance_time}
\end{figure}

\subsection{Analyzes of the Initial Factor Distance}

The \VSDMOEA{} induces the diversity of the decision variable space through the initial distance factor ($D_I$), such parameter is decreased as the number of generations elapses.
%
Given that this parameter influences the performance of the algorithm, a detailed empirical analyzes is taken into account as follows.
%
Since that this parameter is computed as a fraction of the main normalized diagonal which belongs to the unitary hyper-cube, the portions considered are $ D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\}$.
%
In the Figure \ref{fig:Initial-distance-factor} is shown the general mean of the \HV{} for each configuration with two and three objectives respectively.
%
Particularly, the initial parameter $D_I=0.0$, which does not promote diversity, should have a similar performance than a classic \MOEA{}.
%
In spite that none diversity is promoted, the \VSDMOEA{} achieves better general mean values than the remaining \MOEAS{}, those values are $0.905$, $0.895$ for two and three objectives respectively.
%
Even more, the benefits of promoting diversity are outstanding from $0.909$ and $0.895$ of two and three objectives to $0.936$ and $0.899$ with $D_I=0.1$.
%
It seems that such benefits are more notorious with two objectives than with three.
%
This might occurs given that the population size might not been enough to cover the entire objective space.
%
Based on this empirical results, the most suitable parameter configuration should be set with $D_I = 0.4$.
%
\begin{figure}[t]
\centering
\input{Graphic-Initial-Distance.tex}
\label{fig:Initial-distance-factor}
\end{figure}



\input{Tables/Table_HV_2obj.tex}
\input{Tables/Table_HV_3obj.tex}
%\input{Tables/Table_IGDP_2obj.tex}
%\input{Tables/Table_IGDP_3obj.tex}
\input{Tables/Tests_HV_2obj.tex}
\input{Tables/Tests_HV_3obj.tex}
%\input{Tables/Tests_IGDP_2obj.tex}
%\input{Tables/Tests_IGDP_3obj.tex}
