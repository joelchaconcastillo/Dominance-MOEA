\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG1.tex}
\label{fig:Diversity_WFG1}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG5.tex}
\label{fig:Diversity_WFG5}
\end{figure}




\begin{figure}[t]
\centering
\input{Graphic-Performance-Time.tex}
\label{fig:Performance_time}
\end{figure}



In this section the experimental validation is carried out, showing that controlling the diversity in the variable space is a way to improve further some of the results obtained by state-of-art-MOEAs --principally with the difficultest problems--, thus several theorical especifications are explained.
%
At first, the validation scheme with the \VSDMOEA{} and the state-of-the-art MOEAs is described.
%
Thereafter, an analyzes of the scalability in the decision variables is presented.
%
In the same line, a sensitivity experiment of the initial factor distance parameter ($D_I$) required by the \VSDMOEA{} is reported.
%
Given the well-known issue of premature convergence in MOEAs, an analyzes of the diversity in the decision variable space through the elapsed time is driven.
%
Since, the \VSDMOEA{} is highly-dependent of the total execution time it is taken into account through several term-executions.


%


% which belong to jMetalcpp~\cite{Joel:JMETAL} framework.
%
To validate the proposed MOEA in this work are considered some of the most popular benchmark in the multi-objective field.
%
Particularly, the WFG \cite{Joel:WFG}, DTLZ \cite{Joel:DTLZ}  and UF \cite{Joel:CEC2009}  test problems have been used for our purpose. 
%
%Through the literature several crossover operators have been proposed in MOEAs~\cite{Joel:ParentMeanCentricSelfAdaptation},  
%a popular operator is the Simulated Binary Crossover (SBX).4\cite{Joel:SBX1994}%, Joel:TAXONOMY_CROSSOVER, Joel:Kalyanmoy}
Additionally, our experimental validation includes the VSD-MOEA, as well as three well-known state-of-the-art algorithms.
%
Given that all of them are stochastic algorithms, each execution was repeated 35 times with different seeds.
%
The common configuration in all of them was the following: the stopping criterion was set to $250,000$ generations, the population size was fixed to $100$, the WFG test problems were configured with two and three objectives, which are setted to 24 parameters, where 20 of them are distance parameters, and 4 are position parameters.
%
Additinally, in the DTLZ test instances, the number of decision variables is setted to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7 respectively, as is suggested by the authors \cite{Joel:DTLZ}.  
% 
The UF benchmark is composed of ten test instances, which is categorized in two groups bases in the number of objetive funcitons to solve, thus the former seven consists of two objectives and the latter of three objectives, where the number of decision variables taken into account in each one is $n=30$.
%
In general, the crossover and mutation operators are the Simulated Binary Crossover (SBX), and polynomial~\cite{Joel:SBX1994, Joel:Mutation}, which probabilities are setted to $0.9$ and $1/n$ respectively.
%
Also, the crossover and mutation distribution indexes were assigned to $20$ and $50$ respectively.
%
The extra-parametrization of each algorithm is showed in the table~\ref{tab:Parametrization}.
%
\begin{table}[t]
\centering
\caption{Parameterization of each MOEA considered}
\label{tab:Parametrization}
\begin{tabular}{l|l}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
R2-MOEA & \\ \hline
MOEA/D & \begin{tabular}[c]{@{}l@{}}size of neighborhood,= 20, \\ max updates by sub-problem (nr) = 2 and $\delta = 0.9$\end{tabular} \\ \hline
VSD-MOEA & $D_I=\sqrt{n}*0.25$ \\ \hline
\end{tabular}
\end{table}

%\begin{itemize}
% %\scriptsize
% \item \textbf{GDE3}: CR = 0.9 and F = 0.5.
% \item \textbf{MOMBI-II}: $\epsilon = 1e-3$, $\alpha = 0.5$, record size = 5 generations. 
% \item \textbf{MOEA/D}: size of neighborhood  = 20, max updates by sub-problem (nr) = 2 and $\delta = 0.9$.
% \item \textbf{VSD-MOEA}: $D_I=\sqrt{n}*0.25$.
% \end{itemize}

Particularly, the algorithms MOEA/D and MOMBI-II require a set of vectors uniformly scattered on the unit-simplex, therefore the number of vectors generated increases nonlinearly with the number of objectives.
%
Consequently, is applied the method proposed in \cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres} where the uniform design (UD) \cite{Joel:Uniform_Design} and good lattice point (glp) are combined.
%
Thus the number weight of vectors is not affected by the number of objectives.

In addition, our experimental analysis has been carry out with the hypervolume indicator, since the WFG benchmark variate the Pareto front shape with different distance parameters \cite{Joel:ScalabilityStudy}.
%

In this work the reference points are chosen to be a vector with values slightly larger than the nadir point, also for complex problems the reference point is considered as nadir point plus the unity.
%
Therefore the reference points implemented in the hypervolume indicator are showed in the table \ref{tab:ReferencePoints} as used in \cite{Joel:Kuhn_Munkres, Joel:OperatorAHX}.

\begin{table}[t]
\centering
\caption{References points for the HV indicator}
\label{tab:ReferencePoints}
\begin{tabular}{cc}
\hline
\textbf{Instances} & \textbf{Reference Point} \\ \hline
WFG1-WFG9 & $[2.1, ...,2m+0.1]$ \\
DTLZ 1, 2, 4 & $[1.1, ..., 1.1]$ \\
DTLZ 3, 5, 6 & $[3, ..., 3]$ \\
DTLZ7 & $[1.1, ..., 1.1, 2m]$ \\
UF 1-10 & $[2, ..., 2]$ \\ \hline
\end{tabular}
\end{table}
%
In order to statistically compare the hypervolume results, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whatever or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the nonparametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, if the mean and median obtained by $X$ are higher than the mean and median achieved by $Y$.

%

In the tables \ref{tab:StatisticsHV_2obj}, \ref{tab:StatisticsHV_3obj} are showed the hypervolume statistics with two an three objectives respectively.
%
The column \textit{Diff} indicate how far is the best HV mean from each algorithm, this field is computed as the difference between the mean of the each algorithm and the best mean.
%
Consequently, the best algorithm in each instance has assigned a zero.
%

Considering two objectives the GDE3 provides the best results, however the VSD-MOEA is very close to the GDE3 as is showed in the \textit{Diff} columns.
%
It is important to highlight that the DTLZ test suites have the next weaknesses \cite{Joel:CEC2009}.
The global optimum lies in the center or bounds, all are separable and the global optimum has the same parameter values for different dimensions.
%
Particularly the DTLZ5 and DTLZ6 are easy for the GDE3, since the global optimal are located in the low bound, thus if the differential operators locate a solution outside of bounds, the repair procedure could move the point among the optimal.

%
Additionally, the GDE3 get worse according increases the number of objectives, even more the \textit{Diff} results are in average high, except for the DTLZ5 and DTLZ6 where the optimal set are located along the bounds.
%
Despite the fact that the VSD-MOEA does not have a repair procedure because it implements genetic operators, the results are fairly stable.
%
Also improves the hypervolume with three objectives, hence can be considered a robust algorithm, in fact considering more objectives it provides better results than the dominance-based algorithms\footnote{Experimentally with ten objectives the algorithm is best than dominance-based MOEAs.}.
%
A remarkable characteristic that can be appreciated in two and three objectives is that our  proposal provide the best results in the most difficult problems as are dependence, multi-modal and deceptiveness.

%
On average the VSD-EMOA has lower \textit{Diff} value than the rest of algorithms, therefore considering all best mean of each instance, the VSD-EMOA is not too far from the best means.
%
Even more, the min and max averages are better than the min and max of the state-of-art algorithms.
%

The effective test showed in the tables \ref{tab:Effective_Test_2obj}, \ref{tab:Effective_Test_3obj} are conformed by two an three objectives respectively,  these metrics qualify the superiority of each algorithm with the rest through pair comparisons.
%
Thus, an algorithm \textbf{A} is compared with algorithm \textbf{B}, if \textbf{A} wins, the difference with \textbf{B} is accumulated in wins $\uparrow$ of the algorithm \textbf{A}, the same process is for the algorithm \textbf{B} but it is accumulated in the lost field $\downarrow$.
%
The column \textit{Score} is conformed by the difference between the win and lost values, therefore a high positive score indicate the superiority of the algorithm.
%

In addition, our proposal has low negative scores in the DTLZ6 and WFG6 with two objectives, it might occurs because these instances are not a problem to long term executions, therefore they are totally defined by the crowding procedure.
%
However, the negative scores in VSD-MOEA are not highly significant.
%
Additionally, considering three objectives, the VSD-MOEA provides the best and positive scores.
%
In general our proposal has the best scores in difficult instances as are the UF and some WFG problems.

\subsection{Decision Variable Scalability Experiments}

The scalability of each MOEA is also evaluated respect with the number of decision variables \cite{Joel:ScalabilityStudy}. 
%
The figures \ref{fig:Scalability_Study_HV_1}, \ref{fig:Scalability_Study_HV_2} show the hypervolume performance of 30, 100, 250 and 500 variables respectively.
%
Particularly,  the scalability study was realized in DTLZ4, UF5 with two objectives and DTLZ4, UF10 with three objectives.
%
In some instances the GDE3 degrades relatively fast according increases the number of decision variables as is showed in UF5, UF10 and DTLZ4 with three objectives.
%
Also, the GDE3 show a non-stable performance with the parameter configurations, as is explained by J. Lampinen et al.\cite{Joel:GDE3_CEC09}, where they indicate that a high value for CR might lead to premature convergence with respect to one objective compared to another.

%
Specifically, the instance UF10 with GDE3 has an increment of HV for 100 variables, this irregularity is related with diversity issues \cite{Joel:GDE3_CEC09}
%
On the other hand the VSD-MOEA is enough stable, also it provides the best HV values.
%
It is interesting that the MOEA/D and MOMBI-II required an extra-parametrization, hence the stability could be compromised.

%
The 50\% attainment surfaces WFG2, WFG8 and DTLZ7 instances are showed in the figure \ref{fig:Attainment_Surfaces}.
%
The analyses shows that our proposal provide solutions approximated to the Pareto front.
%
Although the GDE3 approximate the WFG2 and DTLZ7, this this algorithm is far in some regions of the Pareto front with the WFG8 instance. 

\begin{figure}[t]
\centering
\input{Graphic-Scalability-2obj.tex}
\label{fig:variable-decision-scalability-2obj}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Scalability-3obj.tex}
\label{fig:variable-decision-scalability-3obj}
\end{figure}

\subsection{Analyzes of the Intial Factor Distance}

\begin{figure}[t]
\centering
\input{Graphic-Initial-Distance.tex}
\label{fig:Initial-distance-factor}
\end{figure}

\subsection{Convergence of the Diversity of WFG1}
\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG1.tex}
\label{fig:Diversity_WFG1}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG5.tex}
\label{fig:Diversity_WFG5}
\end{figure}

\subsection{Improving Dependece on the Execution}


\input{Tables/Table_HV_2obj.tex}
\input{Tables/Table_HV_3obj.tex}
\input{Tables/Table_IGDP_2obj.tex}
\input{Tables/Table_IGDP_3obj.tex}
\input{Tables/Tests_HV_2obj.tex}
\input{Tables/Tests_HV_3obj.tex}
\input{Tables/Tests_IGDP_2obj.tex}
\input{Tables/Tests_IGDP_3obj.tex}
