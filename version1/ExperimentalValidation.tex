In this section the experimental validation is carried out, showing that controlling the diversity in the variable space is a way to improve further some of the results obtained by the state-of-art-MOEAs.
%
At the beginning, several technical specifications taken into account in our comparison outline are explained.
%
Thereafter, to have a broad perception of the \VSDMOEA{} some experiments are driven.
%
Between them an analyzes which is designed to test the scalability in the decision variable space of each \MOEA{}.
%
This analyzes is narrowed through some specific and well known problems.
%
In the same line, with the intention to have a better understanding of the critial parameter that induces the initial amount of diversity is taken into account.
%
This is carried out through several settings and with all the test-problems.
%
Finally, since that the mechanism imposed in our proposal, which avoid the premature convergence, highly depends on the elapsed time, we reported the benefits of it considering both short, and long term executions.
%
The latter experiments shows that the \VSDMOEA{} has a decent performance in short-term executions too.
%

% which belong to jMetalcpp~\cite{Joel:JMETAL} framework.
%
To validate the proposed MOEA in this work are considered some of the most popular benchmark in the multi-objective field.
%
Particularly, the WFG~\cite{Joel:WFG}, DTLZ~\cite{Joel:DTLZ}, and UF~\cite{Joel:CEC2009} test problems have been used for our purpose. 
%
%Through the literature several crossover operators have been proposed in MOEAs~\cite{Joel:ParentMeanCentricSelfAdaptation},  
%a popular operator is the Simulated Binary Crossover (SBX).4\cite{Joel:SBX1994}%, Joel:TAXONOMY_CROSSOVER, Joel:Kalyanmoy}
Additionally, our experimental validation includes the \VSDMOEA{}, as well as three well-known state-of-the-art algorithms.
%
Given that all of them are stochastic algorithms, each execution was repeated $35$ times with different seeds.
%
The common configuration in all of them was the following: the stopping criterion was set to $250,000$ generations, the population size was fixed to $100$, the WFG test problems were configured with two and three objectives, which are setted to $24$ parameters, where $20$ of them are distance parameters, and $4$ are position parameters.
%
Additinally, in the DTLZ test instances, the number of decision variables is setted to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7 respectively, as is suggested by the authors \cite{Joel:DTLZ}.  
% 
The UF benchmark is composed of ten test instances, which is categorized in two groups that are based in the number of objetive functions to solve, thus the first seven consists of two objectives, and the reaming of three, alsoalso  the number of decision variables taken into account in each one is $n=30$.
%
In general, the crossover and mutation operators are the Simulated Binary Crossover (SBX), and polynomial~\cite{Joel:SBX1994, Joel:Mutation}, which probabilities are setted to $0.9$ and $1/n$ respectively.
%
Also, the crossover and mutation distribution indexes were assigned to $20$ and $50$ respectively.
%
The extra-parameterization of each algorithm is showed in the table~\ref{tab:Parametrization}.
%
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[t]
\centering
\caption{Parameterization of each MOEA considered}
\label{tab:Parametrization}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{\textbf{MOEA/D}} &Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbour size = 10, \\
 & period utility updating = 30 generations \\ 
 & probability local selection ($\delta$) = 0.9,\\ \hline
\textbf{VSD-MOEA} & $D_I=0.4$ \\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\end{tabular}
\end{table}


Despite the fact that the \MOEAD{}, and \RMOEA{} can be employed with the same utility function --in this case the Tchebycheff function-- each one of them is designed through a notorious dissimilar paradigm.
%
Thus, the weight vectors taken into consideration for each one of them were different.
%, i.e. the confias it was originally proposed by the authors. 
%
The main reason of this, is that the \RMOEA{} can be configured with a different population size than the number of weight vectors without been significantly affected on its performance.
%
Particularly, the \RMOEA{} employes $501$ and $496$ weight vectors for two and three objectives respectively.
%
Contrarily, in the \MOEAD{} each weight vector is identified as a subproblem, therefore the population should correpond to the number of weight vectors.
%
Also, the weight vectors used in the \MOEAD{} should be uniformly scattered on the unit-simplex, however it can be a complication since that the number of vectors requiered for this task increases non-linearly according the number of objectives.
%
Therefore, in this version is appled the method proposed in \cite{Joel:MOEAD_Uniform_Design, Joel:Kuhn_Munkres} where the uniform design (UD) \cite{Joel:Uniform_Design} and good lattice point (GLP) are combined.
%
In this way, the number of weight vectors that is required by this \MOEA{} is not affected by the number of objectives.


Mainly, the experimental analyzes is carried out considering the hypervolume indicator (\HV{}).
%
The \HV{} metric measures the size of the objective space dominated by the approximated solutions given a reference point, so the solutions dominated by the reference point are not considered.
%
Particularly, the reference point is chosen to be a vector which values are sightly larger (ten percent) than the nadir point as is suggested in \cite{ishibuchi2017reference}.
%
Similarly that in \cite{li2015evolutionary}, and to have a fair comparison the normalized \HV{} is taken into account.
%
Specifically, the \HV{} reported is obtained as the division between the \HV{} reached by a set of solutions and the \HV{} of the optimal Pareto Front.
%
In this way, the more approximate to unity this metric is, the more a \MOEA{} reaches to the Pareto Front.
%



%%\begin{table}[t]
%%\centering
%%\caption{References points for the HV indicator}
%%\label{tab:ReferencePoints}
%%\begin{tabular}{cc}
%%\hline
%%\textbf{Instances} & \textbf{Reference Point} \\ \hline
%%WFG1-WFG9 & $[2.1, ...,2m+0.1]$ \\
%%DTLZ 1, 2, 4 & $[1.1, ..., 1.1]$ \\
%%DTLZ 3, 5, 6 & $[3, ..., 3]$ \\
%%DTLZ7 & $[1.1, ..., 1.1, 2m]$ \\
%%UF 1-10 & $[2, ..., 2]$ \\ \hline
%%\end{tabular}
%%\end{table}
%
In order to statistically compare the \HV{} results, a similar guideline than the proposed in~\cite{Joel:StatisticalTest} was used. 
%
First a Shapiro-Wilk test was performed to check whatever or not the values of the results followed a Gaussian distribution. 
%
If, so, the Levene test was used to check for the homogeneity of the variances. 
%
If samples had equal variance, an ANOVA test was done; if not, a Welch test was performed. 
%
For non-Gaussian distributions, the nonparametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution. 
%
An algorithm $X$ is said to win algorithm $Y$ when the differences between them are statistically significant, if the mean and median obtained by $X$ are higher than the mean and median achieved by $Y$.
%

In the tables \ref{tab:StatisticsHV_2obj}, \ref{tab:StatisticsHV_3obj} are showed the normalized hypervolume with two an three objectives respectively.
%
From this empirical results, it is clear that the \VSDMOEA{} obteained the highest general mean \HV{} with both two and three objectives.
%
Even more, the standard deviation is the lowest in almost all the problems, thus this \MOEA{} shows to be stable, meaning that reach similar results with differents seeds.
%
The best general mean (last row) considering two objectives is achieved by the \VSDMOEA{} with $0.955$.
%
Also, the second general mean is obtained by the \NSGAII{} with $0.886$.
%
It is important to remark that the general mean can be unsteady, this mean that very low \HV{} values could affect highly this measurement.
%
However, all the state-of-the-art-\MOEAS{} achieved a general mean of $0.88$ considering two objectives, whilst the \VSDMOEA{} obtained $0.95$.
%
Considering three objectives the performance of the \NSGAII{} is highly affected, this might occurs since that density estimator employed in the \NSGAII{} highly depends on the dominance-relation, thus in some problems (e.g. multi-frontal problems UF10) the solutions do not converge adequatly to the Pareto front.
%
In the same line, the \VSDMOEA{} achieved the best \HV{} values in almost all the problems, in fact such values that are higher than $0.9$ are close enough to the Pareto Front.
%
The second best \MOEA{} based in the general mean is the \RMOEA{} with $0.855$, despite that it adopts the same utility function that the \MOEAD{}, the latter is lightly lower with $0.835$, this might occurs given that the \MOEAD{} has several paremeters to be tunned, and the selected configuration could be insuficient to long-term executions.
%


In the tables \ref{tab:Tests_HV_2obj} and \ref{tab:Tests_HV_3obj} are showed the statistical tests with two and three objectives respectively.
%
In the column tagged ``Diff'' is computed the difference between the mean of each algorithm and the best mean achieved.
%
Taking into account two objectives the \VSDMOEA{} achieved $52$ wins, in comparison the \RMOEA{} has $34$ wins.
%
In spite that the \NSGAII{} achieved a better general mean, it won less times that the remaining \MOEAS{}.
%
Meaning that the \NSGAII{} obtains values close enough than the best \MOEA{}, this can be viewed in the last row where is computed the total sum of all the problems.
%
Generally speaking, the best results are obtained by the \VSDMOEA{}, since that the total sum of the ``Diff'' column is $0.061$, thus when this algorithm does not achieved the best results, it obtained near solutions to the best results.
%
Futhermore, the algorithms \RMOEA{} and \MOEAD{} achieved a similar total ``Diff'' values.
%
Particularly, the worst ``Diff'' value achieved by the \VSDMOEA{} is in the problem WFG6.
%
This problem is unimodal and non-separable, and this occurs since that the initial factor distance is very high, in fact through other experimental analyzes this instance was correctly solved with $D_I=0.1$ which mean achieved in this problem was of $0.917$ and $0.868$ for two and three objectievs respectively.
%
In addition, inspecting three objectives (table \ref{tab:Tests_HV_3obj}) it can be seen similar results, notably the \VSDMOEA{} improves its performance respectively to the remaining \MOEAS{}.
%
Particularly, the most complicated problems are better solved by the \VSDMOEA{} as are UF3, UF4, UF5, and UF6 in two objectives, and UF9, UF10 in three objectives.
%
The UF5 is considered as one of the most difficult problems since that the optimal Pareto front is conformed by $21$ points, also it has several suboptimal regions where the solutions can be stuck. 
%
Neverthless, since that it is a disconected front, the \MOEAS{} that considers weight vectors have more chances to get stuck.
%
It is showed, since that the \NSGAII{} has a lower ``Diff'' value ($0.048$) than the \MOEAD{} and \RMOEA{} ($0.205$ and $0.122$).
%
Diversely, the UF10 is a multi-frontal problem, this means that there exists different optimal non-dominated fronts that correspond to different locally optimal values \cite{huband2006review}, this characteristic increases the difficultness of the problem as the number of objectives increases.
%
Indeed, the latter problem has notably converged better in \VSDMOEA{} than the reamining \MOEAS{}.
%

%

%The column \textit{Diff} indicate how far is the best HV mean from each algorithm, this field is computed as the difference between the mean of the each algorithm and the best mean.
%
%Consequently, the best algorithm in each instance has assigned a zero.
%

%It is important to highlight that the DTLZ test suites have the next weaknesses \cite{Joel:CEC2009}.
%The global optimum lies in the center or bounds, all are separable and the global optimum has the same parameter values for different dimensions.
%
%Particularly the DTLZ5 and DTLZ6 are easy for the GDE3, since the global optimal are located in the low bound, thus if the differential operators locate a solution outside of bounds, the repair procedure could move the point among the optimal.

%
%Additionally, the GDE3 get worse according increases the number of objectives, even more the \textit{Diff} results are in average high, except for the DTLZ5 and DTLZ6 where the optimal set are located along the bounds.
%
%Despite the fact that the VSD-MOEA does not have a repair procedure because it implements genetic operators, the results are fairly stable.
%

%Also improves the hypervolume with three objectives, hence can be considered a robust algorithm, in fact considering more objectives it provides better results than the dominance-based algorithms\footnote{Experimentally with ten objectives the algorithm is best than dominance-based MOEAs.}.
%
%A remarkable characteristic that can be appreciated in two and three objectives is that our  proposal provide the best results in the most difficult problems as are dependence, multi-modal and deceptiveness.

%
%On average the VSD-EMOA has lower \textit{Diff} value than the rest of algorithms, therefore considering all best mean of each instance, the VSD-EMOA is not too far from the best means.
%
%Even more, the min and max averages are better than the min and max of the state-of-art algorithms.
%

%The effective test showed in the tables \ref{tab:Effective_Test_2obj}, \ref{tab:Effective_Test_3obj} are conformed by two an three objectives respectively,  these metrics qualify the superiority of each algorithm with the rest through pair comparisons.
%
%Thus, an algorithm \textbf{A} is compared with algorithm \textbf{B}, if \textbf{A} wins, the difference with \textbf{B} is accumulated in wins $\uparrow$ of the algorithm \textbf{A}, the same process is for the algorithm \textbf{B} but it is accumulated in the lost field $\downarrow$.
%
%The column \textit{Score} is conformed by the difference between the win and lost values, therefore a high positive score indicate the superiority of the algorithm.
%

%In addition, our proposal has low negative scores in the DTLZ6 and WFG6 with two objectives, it might occurs because these instances are not a problem to long term executions, therefore they are totally defined by the crowding procedure.
%
%However, the negative scores in VSD-MOEA are not highly significant.
%
%Additionally, considering three objectives, the VSD-MOEA provides the best and positive scores.
%
%In general our proposal has the best scores in difficult instances as are the UF and some WFG problems.

\subsection{Decision Variable Scalability Experiments}

 
The scalability of each MOEA is also evaluated respect with the number of decision variables \cite{Joel:ScalabilityStudy}. 
%
The figures \ref{fig:variable-decision-scalability-2obj} and \ref{fig:variable-decision-scalability-3obj} show the mean of \HV{} attained with $50$, $100$, $250$, $500$, and $1000$ variables respectively.
%
The scalability study was taken into consideration with some problems conformed by easy and difficult characteristics.
%
Particularly, the problems considered in this analyzes were the DTLZ4, UF5 which are conformed by two objectives, and DTLZ4, UF10 with three objectives.
%
In addition, each selected problem was repeated $35$ times, thus the mean of all the \HV{} values are reported.
%
The \VSDMOEA{} attained the best results in two objectives with both problems, however its remarkable to notice that \HV{} value reported by the \NSGAII{} improves as the number of variables decision is increased.
%
Specifically, the DTLZ4 is uni-modal, and its Pareto shape is concave, also it has a polynomial bias.
%
This interesting behaviour is also showed by the \RMOEA{}, and can be explained as follows.
%
The probability to get stuck in certain sub-optimal regions can be avoided increasing the decision variables space.
%
This highly depends in the operators taken into account (in this case the SBX), thus in some circumstances the more bigger the variable decision space is, the better quality solutions are reached.
%
This can be lightly seen in the \MOEAD{} after $250$ variables, however we believe that this \MOEA{} is highly parameter-sensitive.
%
Contrarily, as the decision variable space is increased in the UF5 the performance of the \MOEAS{} is highly affected, in spite of this the \VSDMOEA{} still attained the best \HV{} values.
%
However, the \VSDMOEA{} is not the best \MOEA{}, it can be seen considering three objectives (figure \ref{fig:variable-decision-scalability-3obj}).
%
Specifically, where the number of variables is increased to one thousand in both problems (DTLZ4 an d UF10).
%
This might occurs for several reasons, perhaps the most important is related with the distance employed in the variable space (Euclidean distance), this is \textit{The Curse of Dimensionality} \cite{trunk1979problem, beyer1999nearest}.
%
This drawback means that under certain broad conditions, as dimensionality increases, the distance to the nearest neighbor approaches the distance to the farthest neighbor.
%
In other words, the contrast in distances to different data points becomes noexistent.
%
The remaining \MOEAS{} show a similar behavior with the DTLZ4 with two and three objectives.
%
As previoudly mentioned the performance of \VSDMOEA{} is seriourly deteriored, however it is still better than the \NSGAII{}.
%
Also, the \RMOEA{} seems to be enough stable with three objectives in the problems DTLZ4 and UF10.

\begin{figure}[t]
\centering
\input{Graphic-Scalability-2obj.tex}
\label{fig:variable-decision-scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
\input{Graphic-Scalability-3obj.tex}
\label{fig:variable-decision-scalability-3obj}
\end{figure}

\subsection{Analyzes of the Intial Factor Distance}

The \VSDMOEA{} induces the diversity of the decision variable space thorugh the initial distance factor ($D_I$), such parameter is decreased as the number of generations elapses.
%
Given that this paramater influences the performance of the algorithm, a detailed empirical analyzes is taken into account as follows.
%
Since that this parameter is computed as a fraction of the main normalized diagonal which belong to the unitary hypercube, the portions considered are $ D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\}$.
%
In the figure \ref{fig:Initial-distance-factor} is shown the general mean of the \HV{} for each configuration with two and three objectives respectively.
%
Particularly, the initial parameter $D_I=0.0$, which does not promote diversity, should have a similar performance than a classic \MOEA{}.
%
In spite that none diversity is promoted, the \VSDMOEA{} achieves better general mean values than the remaining \MOEAS{}, those values are $0.905$, $0.895$ for two and three objectives respectively.
%
Even more, the benefits of promoting diversity are outstanding.
%
It seems that such benefits are more notorius with two objectives than with three.
%
This might occurs given that the population size could not been enough to cover the entire objective space.
%
Giving this empirical results, the most suitable parameter configuration should be setted with $D_I = 0.4$.
%
\begin{figure}[t]
\centering
\input{Graphic-Initial-Distance.tex}
\label{fig:Initial-distance-factor}
\end{figure}

\subsection{Diversity of the \MOEAS{} Through Generations}

In order, to have a better understanding of the diversity behaviour some WFG problems have been selected.
%
The WFG problems divide the decision variables in two kinds of parameter: the distance parameters and the position parameters.
%
A parameter $x_i$ is a distance parameter when for all parameter vectors $\mathbf{a}$, modifying $x_i$ in $\mathbf{a}$ results in a parameter vector that dominates $\mathbf{a}$, is equivalent to $\mathbf{a}$, or is dominated by $\mathbf{a}$.
%
However, if $x_i$ is a position parameter, modifying $x_i$ in $\mathbf{a}$ always results in a vector that is incomparable or equivalent to $\mathbf{a}$~\cite{huband2005scalable}.
%

In this section we show that state-of-the-art-\MOEAS{} do not always maintain high enough diversity.
%
Particularly, the selected problems are used to show that premature convergence appears in the set of distance parameters.
%
Consequently, the operators involved lose its exploraty strength.
%
We select the WFG1, WFG5, and WFG6 problems, because they have simple definition, but most MOEAs faces difficulties with them. 
%
In addition, those problems were taken into account given that the WFG1 and WFG5 were better solved by the \VSDMOEA{}.
%
Generally speaking, the WFG1 converged to the Pareto Front with our proposal, this since that the accuracy obtained was of $0.993$.
%
In contrast, the WFG5 was still far away of the pareto Front which \HV{} mean  was of $0.923$.
%
Contrarily, the WFG6 was chosen since that the \VSDMOEA{} achieved the worst results.
%
Whereas the WFG1 and WFG6 are uni-modal, the WFG5 is a highly deceptive problem.
%
Also, the WFG1 and WFG5 are conformed by separable properties in the objective functions.
%
In fact, the distance parameters values associated to Pareto optimal solutions for WFG1-WFG7 have exactly the same values in the distance parameters.
%
This values is shown as follows:
\begin{equation}
   x_{i=k+1:n} = 2i \times 0.35
\end{equation}
%
Taking into account the sochastic behavior of \MOEAS{}, $35$ independent executions were run by each selected problem.
%
In all of them, the stopping criterion was set to $250,000$ generations.
%
In order to analyze the diversity, the average Euclidean distance among individuals (ADI) is calculated, i.e. the mean value of all pairwise distances among individuals in the population is reported.
%
In the figures \ref{fig:Diversity_WFG1}, \ref{fig:Diversity_WFG5}, and \ref{fig:Diversity_WFG6} are showed the evolution of diversity of the WFG1, WFG5, and WFG6 respectively.
%
In those figures each \MOEA{} is showed by dashed and solid lines that represents two and three objectives respectively.
%
Particularly, the \VSDMOEA{} properly maintains diversity in both kind of parameters, while in the remaining algorithms the diversity in the distance parameters is lost after the $10\%$ (generation $2500$) of total generations.
%
Thus, after those \MOEAS{} converges, they are bascally modifying the position parameters, so the majority of the time is improving further the diversity in the objectives space and the convergency is neglected.
%
In fact, this diversity issue is also present in the WFG5.
%
However, all the \MOEAS{} have a minimum lower bound of diversity in the position parameters of those selected problems.
%
Contrastively, considering the WFG6 (figure \ref{fig:Diversity_WFG5}) the \VSDMOEA{} does not converge at all in the distance parameters with three objectives, this might be an effect of promoting too much diversity.
%
Besides this issue, the \VSDMOEA{} still achieves the best \HV{} values.
%
In addition, this drawback is more notorious in the problem WFG6, in fact both two and three objectives does not converged in the distance parameters, and the position variables are still more diversified as usual.


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG1.tex}
\label{fig:Diversity_WFG1}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG5.tex}
\label{fig:Diversity_WFG5}
\end{figure}


\begin{figure}[t]
\centering
\input{Graphic-Diversity_WFG6.tex}
\label{fig:Diversity_WFG6}
\end{figure}


\subsection{Performance of the \MOEAS{} Related with the Criteria Stop}

In spite that the \VSDMOEA{} is specially designed to attain quality solutions in long-term executions.
%
In this section is showed the performance of the \MOEAS{} variating the criteria stop.
%
Mainly, three ranges of criteria stop were reviwed.
%
Each range was split in ten intervals, such ranges considered were $[300, 2500]$, $[2500, 25000]$ and $[25000, 250000]$ respectively.
%
In the figure \ref{fig:Performance_time} are showed the mean \HV{} values attained with each \MOEA{} with two and three objectives respectively.
%
This shows that the \VSDMOEA{} attains the worst \HV{} values considering only $300$ generations.
%
However, as the number of generations increases the \HV{} values are improved significatly, in fact after $2500$ generations the \VSDMOEA{} has a notorious improvement respect to the state-of-the-art-\MOEAS{} in both two and three objectives.
%
It can be seen that as the maximum number of generations is higher than $25000$ the remaining \MOEAS{} seems to be stuck, specifically considering two objectives.
%
In spite that in three objectives the \RMOEA{} shows an improvement after $100000$ generations, it still has lower values than the \VSDMOEA{}.
%
In addition, taking into account three objectives the best general mean value achieved was above $0.9$, there is still possible that increasing the number of generations the \VSDMOEA{} achieves better results.
%
However, in some situations, as seems to be in the case of two objetive, could not be available achieved a better accuracy, and a upper bound could be present.
%
Its significant important to note how the performance of the \NSGAII{} is degreaded in three objectives, differntly to the \RMOEA{} and the \MOEAD{}.
%
Even more, the \MOEAD{} seems to be stuck after $25000$ generations, this might occurs for the greedy selection approach that this \MOEA{} has incorpored.
%
In fact the \MOEAD{} attained better results than the \RMOEA{} in short-term executions.
%

\begin{figure}[t]
\centering
\input{Graphic-Performance-Time.tex}
\label{fig:Performance_time}
\end{figure}



\input{Tables/Table_HV_2obj.tex}
\input{Tables/Table_HV_3obj.tex}
%\input{Tables/Table_IGDP_2obj.tex}
%\input{Tables/Table_IGDP_3obj.tex}
\input{Tables/Tests_HV_2obj.tex}
\input{Tables/Tests_HV_3obj.tex}
%\input{Tables/Tests_IGDP_2obj.tex}
%\input{Tables/Tests_IGDP_3obj.tex}
